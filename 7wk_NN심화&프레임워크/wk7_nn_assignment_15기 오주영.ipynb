{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN심화.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNfwcipRBlNgzyj6baDJu95"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJQI96Sf2Dyk","executionInfo":{"status":"ok","timestamp":1615962230230,"user_tz":-540,"elapsed":23389,"user":{"displayName":"­오주영[경영학부]","photoUrl":"","userId":"16696704859920156378"}},"outputId":"4edb8125-380b-4a3f-affd-e0b2124ef96a"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import warnings\r\n","from tqdm import tqdm\r\n","from sklearn.model_selection import train_test_split, StratifiedKFold\r\n","from google.colab import drive\r\n","import torch\r\n","import torchvision\r\n","import torch.nn as nn\r\n","from torch.utils.data import Dataset, DataLoader\r\n","from torchvision import transforms\r\n","from torch.autograd import Variable\r\n","import tensorflow as tf\r\n","\r\n","\r\n","drive.mount('./gdrive', force_remount=True)\r\n","plt.rc('axes', unicode_minus=False)\r\n","warnings.filterwarnings(action='ignore')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at ./gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pLr-j1vo2mCn"},"source":["train = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/tobigs15-mnist-competition/train_df.csv\")\r\n","test = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/tobigs15-mnist-competition/test_df.csv\")\r\n","sample_submission = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/tobigs15-mnist-competition/sample_submission.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PrvbotMj2unr"},"source":["#### 1. pytorch : resnet을 구현하여 data augmentation + kfold ensemble"]},{"cell_type":"code","metadata":{"id":"gJlv09h22rdW"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n","\r\n","label = torch.LongTensor(train['label'].values)\r\n","train = torch.FloatTensor(np.array(train.iloc[:, 1:] / 255).reshape((-1, 1, 28, 28)))\r\n","test = torch.FloatTensor(np.array(test.iloc[:, 1:] / 255).reshape((-1, 1, 28, 28)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"krBq1qpV2tSk"},"source":["# augmentation이 가능하도록 dataset class를 상속받아 새로운 train dataset을 정의합니다.\r\n","\r\n","class CustomedDataset(Dataset):\r\n","  def __init__(self, img, label, transforms = None):\r\n","    self.img = img\r\n","    self.label = label\r\n","    self.transforms = transforms\r\n","  \r\n","  def __len__(self):\r\n","    return len(self.img)\r\n","  \r\n","  def __getitem__(self, idx):\r\n","    image = self.img[idx]\r\n","    target = self.label[idx]\r\n","    if self.transforms:\r\n","      image = self.transforms(image)\r\n","    return image, target"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkR_5BBw3SER"},"source":["# image만 return하도록 test dataset을 정의합니다.\r\n","\r\n","class TestDataset(Dataset):\r\n","  def __init__(self, img):\r\n","    self.img = img\r\n","    \r\n","  def __len__(self):\r\n","    return len(self.img)\r\n","  \r\n","  def __getitem__(self, idx):\r\n","    image = self.img[idx]\r\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vpYMrN63TTr"},"source":["kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 317)\r\n","# validation으로 손실되는 데이터셋을 없애기 위해 kfold앙상블을 진행합니다\r\n","\r\n","BATCH_SIZE = 8\r\n","\r\n","transformation = transforms.Compose([transforms.RandomResizedCrop(size = (28, 28), scale = (0.8, 1)),\r\n","                                     transforms.RandomAffine(degrees = 30)])\r\n","# data augmentation을 위해 cropping을 하고 이미지르 회전시킵니다"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rEVeqBK3sB5"},"source":["# resnet에 가장 기본이 되는 cnn block을 정의합니다.\r\n","# convolutional - batch normalization - activation 순으로 진행됩니다.\r\n","\r\n","class Conv_block(nn.Module):\r\n","  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\r\n","    super(Conv_block, self).__init__()\r\n","    self.conv = nn.Conv2d(in_channels = in_channels,\r\n","                          out_channels = out_channels,\r\n","                          kernel_size = kernel_size,\r\n","                          stride = stride,\r\n","                          padding = padding,\r\n","                          bias = False)\r\n","    self.bn = nn.BatchNorm2d(out_channels)\r\n","    self.relu = nn.LeakyReLU()\r\n","  \r\n","  def forward(self, x):\r\n","    return self.relu(self.bn(self.conv(x)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"veW9Djv14Iq3"},"source":["# resnet 중간중간 image의 size를 줄여줄 때 사용하는 block을 정의합니다.\r\n","# pooling을 사용하는 대신 convolutional 연산에서 stride를 높여 image의 size를 줄입니다.\r\n","# kernel_size가 1인 kernel을 사용하여 parameter의 수를 효과적으로 줄이고 층은 깊게 쌓을 수 있습니다.\r\n","\r\n","class Connection_conv(nn.Module):\r\n","  def __init__(self, in_channels):\r\n","    super(Connection_conv, self).__init__()\r\n","    self.block1 = Conv_block(in_channels = in_channels, out_channels = int(in_channels/2), kernel_size = 1, stride = 1, padding = 0)\r\n","    self.block2 = Conv_block(in_channels = int(in_channels/2), out_channels = int(in_channels/2), kernel_size = 3, stride = 2, padding = 1)\r\n","    self.conv3 = nn.Conv2d(in_channels = int(in_channels/2), out_channels = in_channels * 2, kernel_size = 1, stride = 1, padding = 0, bias = False)\r\n","    self.bn1 = nn.BatchNorm2d(in_channels * 2)\r\n","    self.relu = nn.LeakyReLU()\r\n","\r\n","    self.con_conv = nn.Conv2d(in_channels = in_channels, out_channels = in_channels * 2, kernel_size = 3, stride = 2, padding = 1, bias = False)\r\n","    self.bn2 = nn.BatchNorm2d(in_channels * 2)\r\n","\r\n","  def forward(self, x):\r\n","    x_ = x\r\n","    x = self.block1(x)\r\n","    x = self.block2(x)\r\n","    x = self.conv3(x)\r\n","    x = self.bn1(x)\r\n","    \r\n","    x_ = self.con_conv(x_)\r\n","    x_ = self.bn2(x_)\r\n","    \r\n","    x = x_ + x\r\n","    x = self.relu(x)\r\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPt9zzWp4dbY"},"source":["# image의 size를 줄이지 않을 경우 사용할 block입니다. \r\n","# kernel_size가 1인 kernel을 사용하여 parameter의 수를 효과적으로 줄이고 층은 깊게 쌓을 수 있습니다.\r\n","\r\n","class Connection_identity(nn.Module):\r\n","  def __init__(self, in_channels):\r\n","    super(Connection_identity, self).__init__()\r\n","    self.block1 = Conv_block(in_channels = in_channels, out_channels = int(in_channels / 4), kernel_size = 1, stride = 1, padding = 0)\r\n","    self.block2 = Conv_block(in_channels = int(in_channels / 4), out_channels = int(in_channels / 4), kernel_size = 3, stride = 1, padding = 1)\r\n","    self.conv3 = nn.Conv2d(in_channels = int(in_channels / 4), out_channels = in_channels, kernel_size = 1, stride = 1, padding = 0, bias = False)\r\n","    self.bn = nn.BatchNorm2d(in_channels)\r\n","    self.relu = nn.LeakyReLU()\r\n","\r\n","  def forward(self, x):\r\n","    x_ = x\r\n","    x = self.block1(x)\r\n","    x = self.block2(x)\r\n","    x = self.conv3(x)\r\n","    x = self.bn(x)\r\n","\r\n","    x = x_ + x\r\n","    x = self.relu(x)\r\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hX9Bg0yM49Rt"},"source":["# resnet에서 global average pooling이후 선형 연산을 위한 block입니다. \r\n","# Linear - batch normalization - activation\r\n","\r\n","class Linear_module(nn.Module):\r\n","  def __init__(self, input_shape, output_shape):\r\n","    super(Linear_module, self).__init__()\r\n","    self.fc = nn.Linear(input_shape, output_shape, bias = False)\r\n","    self.bn = nn.BatchNorm1d(output_shape)\r\n","    self.relu = nn.LeakyReLU()\r\n","  \r\n","  def forward(self, x):\r\n","    x = self.relu(self.bn(self.fc(x)))\r\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6DobBle5Nbr"},"source":["# 위에서 정의한 block들을 활용하여 Resnet을 구현합니다.\r\n","# 코랩을 활용했기 때문에 층을 더 깊게 쌓기에는 연산량의 제약이 있습니다...\r\n","\r\n","class Resnet(nn.Module):\r\n","  def __init__(self):\r\n","    super(Resnet, self).__init__()\r\n","    self.relu = nn.LeakyReLU()\r\n","    self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = (7, 7), stride = 1, padding = 3, bias = False)\r\n","    self.bn1 = nn.BatchNorm2d(16)\r\n","\r\n","    self.block1 = Connection_conv(16)\r\n","    self.block2 = Connection_identity(32)\r\n","    self.block3 = Connection_identity(32)\r\n","\r\n","    self.block4 = Connection_conv(32)\r\n","    self.block5 = Connection_identity(64)\r\n","    self.block6 = Connection_identity(64)\r\n","    self.block7 = Connection_identity(64)\r\n","\r\n","    self.gap = nn.AdaptiveAvgPool2d(1)\r\n","    self.fc1 = Linear_module(64, 32)\r\n","    self.fc2 = nn.Linear(32, 10)\r\n","\r\n","  def forward(self, x):\r\n","    x = self.conv1(x)\r\n","    x = self.bn1(x)\r\n","    x = self.relu(x)\r\n","\r\n","    x = self.block1(x)\r\n","    x = self.block2(x)\r\n","    x = self.block3(x)\r\n","\r\n","    x = self.block4(x)\r\n","    x = self.block5(x)\r\n","    x = self.block6(x)\r\n","    x = self.block7(x)\r\n","\r\n","    x = self.gap(x)\r\n","    x = x.view(-1, 64)\r\n","    x = self.fc1(x)\r\n","    x = self.fc2(x)\r\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQlSNbtQ6PvQ"},"source":["# model을 훈련시킬 함수를 정의합니다. \r\n","# model을 훈련시킬 때와 검증할 때 모두 같은 함수를 사용합니다.\r\n","# phase가 training일 때는 optimizer를 이용하여 model의 parameter를 갱신합니다\r\n","\r\n","def fit(epoch, model, data_loader, phase = 'training'):\r\n","  if phase == 'training':\r\n","    model.train()\r\n","  elif phase == 'validation':\r\n","    model.eval()\r\n","  \r\n","  running_loss = 0\r\n","  running_acc = 0\r\n","\r\n","  total_batch = len(data_loader)\r\n","\r\n","  for batch_idx, (data, target) in enumerate(data_loader):\r\n","    if phase == 'training':\r\n","      optimizer.zero_grad()\r\n","    \r\n","    data, target = data.to(device), target.to(device)\r\n","    output = model(data)\r\n","    pred = output.data.max(dim = 1, keepdim = True)[1]\r\n","    \r\n","    loss = criterion(output, target)\r\n","\r\n","    if phase == 'training':\r\n","      loss.backward()\r\n","      optimizer.step()\r\n","    \r\n","    running_loss += loss / total_batch\r\n","    running_acc += pred.eq(target.data.view_as(pred)).cpu().sum() / BATCH_SIZE / total_batch\r\n","  \r\n","  print('[Epoch: {:>4}] \\t{}_loss = {:>.9} \\t{}_acc = {:>.9}'.format(epoch + 1, phase, running_loss, phase, running_acc))\r\n","  \r\n","  return running_loss, running_acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mumVT1eB7Fy9"},"source":["# 모델의 상태를 저장할 함수를 정의합니다.\r\n","# 모델을 불러와 다시 훈련시킬 때 optimizer가 바뀐다면 훈련 과정에 지장이 있을 수 있으므로 optimizer역시 같이 저장합니다.\r\n","\r\n","def save_checkpoint(epoch, model, optimizer, filename):\r\n","  state = {\r\n","      'Epoch' : epoch,\r\n","      'State_dict' : model.state_dict(),\r\n","      'optimizer' : optimizer.state_dict()\r\n","  }\r\n","  torch.save(state, filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04jNX5-_7avZ"},"source":["# kfold를 사용하여 train dataset과 validation dataset으로 나누어 model을 훈련시킵니다.\r\n","for i, (train_idx, val_idx) in enumerate(kfold.split(train, label)):\r\n","\r\n","  X_train, X_val = train[train_idx], train[val_idx]\r\n","  y_train, y_val = label[train_idx], label[val_idx]\r\n","\r\n","  train_data = CustomedDataset(X_train, y_train, transformation)\r\n","  val_data = CustomedDataset(X_val, y_val)\r\n","\r\n","  train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\r\n","  val_loader = DataLoader(val_data, batch_size = BATCH_SIZE, shuffle = True, drop_last = True)\r\n","\r\n","  model = Resnet().to(device)\r\n","\r\n","  criterion = nn.CrossEntropyLoss().to(device)\r\n","  optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, weight_decay = 3e-6)\r\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'max', factor = 0.5, patience = 7)\r\n","  # model을 훈련시킬 때 overshooting이 자주 발생하는 현상이 있었으므로 ReduceLROnPlateau scheduler를 사용합니다.\r\n","  # 7epoch동안 validation accuracy가 높아지지 않는다면 optimizer의 Learning Rate를 1/2로 줄입니다.\r\n","\r\n","  val_accuracy = [0]\r\n","  PATH = '/content/gdrive/MyDrive/Colab Notebooks/투빅스/cnn_fold%s.pt'%i\r\n","\r\n","  for epoch in range(50):\r\n","\r\n","    epoch_loss, epoch_accuracy = fit(epoch, model, train_loader, phase = 'training')\r\n","    torch.cuda.empty_cache()\r\n","    val_epoch_loss, val_epoch_accuracy = fit(epoch, model, val_loader, phase = 'validation')\r\n","    torch.cuda.empty_cache()\r\n","    scheduler.step(val_epoch_accuracy)\r\n","\r\n","    val_accuracy.append(val_epoch_accuracy)\r\n","\r\n","    if val_epoch_accuracy > max(val_accuracy[:-1]):\r\n","      # validation accuracy가 가장 높은 상태일 때의 모델을 저장합니다.\r\n","      save_checkpoint(epoch + 1, model, optimizer, PATH)\r\n","  \r\n","  print(\"THE BEST ACCURACY OF THIS FOLD IS %s\"%max(val_accuracy))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AGhHngW47aoU"},"source":["# 저장한 모델 5개(kfold에서 k = 5)를 불러옵니다\r\n","\r\n","state0 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/투빅스/cnn_fold0.pt',  map_location=torch.device(device))\r\n","state1 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/투빅스/cnn_fold1.pt',  map_location=torch.device(device))\r\n","state2 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/투빅스/cnn_fold2.pt',  map_location=torch.device(device))\r\n","state3 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/투빅스/cnn_fold3.pt',  map_location=torch.device(device))\r\n","state4 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/투빅스/cnn_fold4.pt',  map_location=torch.device(device))\r\n","\r\n","model0 = Resnet().to(device)\r\n","model1 = Resnet().to(device)\r\n","model2 = Resnet().to(device)\r\n","model3 = Resnet().to(device)\r\n","model4 = Resnet().to(device)\r\n","\r\n","model0.load_state_dict(state0['State_dict'])\r\n","model1.load_state_dict(state1['State_dict'])\r\n","model2.load_state_dict(state2['State_dict'])\r\n","model3.load_state_dict(state3['State_dict'])\r\n","model4.load_state_dict(state4['State_dict'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VANTN-uo8jvU"},"source":["# 앞서 정의한 TestDataset을 사용하여 test_loader를 정의합니다.\r\n","\r\n","test_data = TestDataset(test)\r\n","test_loader = DataLoader(test_data, batch_size = BATCH_SIZE, shuffle = False, drop_last = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaY3_Zpr8jts"},"source":["# test_loader와 model을 이용하여 모델의 예측값을 저장합니다.\r\n","def pred_test(model, test_loader):\r\n","  preds = np.zeros((18000, 10))\r\n","  model.eval()\r\n","\r\n","  for i, data in enumerate(test_loader):\r\n","    data = data.to(device)\r\n","    output = model(data).cpu().detach().numpy()\r\n","    preds[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = output\r\n","  return preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_58QGrK81tn"},"source":["# 훈련에 사용한 crossentropy함수에 softmax함수가 내장돼있으므로 \r\n","# model의 output은 softmax activation을 거치지 않은 상태입니다.\r\n","\r\n","def softmax(x):\r\n","  x_ = x.copy()\r\n","  for i in range(len(x_)):\r\n","    e_x = np.exp(x_[i] - np.max(x_[i]))\r\n","    x_[i] = e_x / e_x.sum()\r\n","  return x_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d4mSZgIv9GCN"},"source":["output0 = softmax(pred_test(model0, test_loader))\r\n","output1 = softmax(pred_test(model1, test_loader))\r\n","output2 = softmax(pred_test(model2, test_loader))\r\n","output3 = softmax(pred_test(model3, test_loader))\r\n","output4 = softmax(pred_test(model4, test_loader))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"slrd28Jb9M5c"},"source":["# 다섯개의 model을 산술평균하여 앙상블합니다.\r\n","torch_ens_output = (output0 + output1 + output2 + output3 + output4) * 0.2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"icJzpTGw9f1p"},"source":["#### 2. Tensorflow : 사전훈련된 densenet모델을 이용하여 kfold ensemble"]},{"cell_type":"code","metadata":{"id":"43I4Alee9M3j"},"source":["train = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/tobigs15-mnist-competition/train_df.csv\")\r\n","test = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/tobigs15-mnist-competition/test_df.csv\")\r\n","sample_submission = pd.read_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/tobigs15-mnist-competition/sample_submission.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Ix9CwR29M1p"},"source":["label = train['label'].values.astype('float32')\r\n","\r\n","train.drop('label', axis = 1, inplace = True)\r\n","train = train.values.astype('float32')\r\n","train /= 255\r\n","train = train.reshape((-1, 28, 28, 1))\r\n","\r\n","test.drop(\"Unnamed: 0\", axis = 1, inplace = True)\r\n","test = test.values.astype('float32')\r\n","test /= 255\r\n","test = test.reshape((-1, 28, 28, 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PBJJPoyk9scJ"},"source":["# tensorflow의 사전학습된 densenet을 이용할 때 이미지의 최소 size는 (32, 32)이므로 padding하여 image의 size를 키워줍니다.\r\n","\r\n","train = np.pad(train, ((0, 0), (2, 2), (2, 2), (0, 0)), mode = 'constant')\r\n","test = np.pad(test, ((0, 0), (2, 2), (2, 2), (0, 0)), mode = 'constant')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vv9gYhdo9sWJ"},"source":["# tensorflow의 사전학습된 densenet을 이용할 때 이미지의 차원은 3차원이어야 하므로 numpy.stack함수를 사용하여 3차원으로 만들어줍니다.\r\n","\r\n","train = np.squeeze(train, axis = -1)\r\n","train = np.stack((train,) * 3, axis = -1)\r\n","\r\n","test = np.squeeze(test, axis = -1)\r\n","test = np.stack((test,) * 3, axis = -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TK5jXtJl-La3"},"source":["# densenet121을 이용하여 모델의 선형층을 떼고, tast에 맞도록 10차원 출력을 가질 수 있게 모델을 정의합니다.\r\n","\r\n","def my_model():\r\n","  bottom = tf.keras.applications.DenseNet121(input_shape = (32, 32, 3), weights = 'imagenet', include_top = False)\r\n","  model = tf.keras.models.Sequential([\r\n","                                      bottom,\r\n","                                      tf.keras.layers.Flatten(),\r\n","                                      tf.keras.layers.Dense(512, activation = 'relu'),\r\n","                                      tf.keras.layers.Dropout(0.25),\r\n","                                      tf.keras.layers.Dense(10, activation = 'softmax')\r\n","  ])\r\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKk0_5a7-eik"},"source":["BATCH_SIZE = 128\r\n","\r\n","kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 923)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NfZWIJD-ehB"},"source":["# data augmentation을 이용하기 위해 ImagedataGenerator함수를 정의합니다.\r\n","# image의 30도 회전, 좌우 20%만큼의 이동, 20%만큼의 확대를 적용합니다.\r\n","# augmentation을 하였을 때 인간이 인식하기에도 같은 사진(같은 숫자)인가를 주의하여 범위를 설정합니다.\r\n","\r\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range = 30,\r\n","                                                          width_shift_range = 0.2,\r\n","                                                          height_shift_range = 0.2,\r\n","                                                          zoom_range = 0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLVzEFUx-efx"},"source":["for i, (train_idx, val_idx) in enumerate(kfold.split(train, label)):\r\n","  X_train, X_val, y_train, y_val = train[train_idx], train[val_idx], label[train_idx], label[val_idx]\r\n","\r\n","  model_path = \"/content/gdrive/MyDrive/Colab Notebooks/투빅스/densenet%s.h5\"%i\r\n","\r\n","  model = my_model()\r\n","\r\n","  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\r\n","                loss = 'sparse_categorical_crossentropy',\r\n","                metrics = ['acc'])\r\n","  \r\n","  # fit_generator함수를 사용하여 모델을 학습합니다. \r\n","  # callback함수를 이용하여 optimizer의 Learning Rate를 변경하고, validation accuracy가 가장 좋은 상태일 때의 모델을 저장합니다.\r\n","  model.fit_generator(datagen.flow(X_train, y_train, batch_size = 128),\r\n","                      epochs = 60,\r\n","                      validation_data = (X_val, y_val),\r\n","                      steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\r\n","                      callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_acc', patience = 15),\r\n","                                   tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_acc', patience = 8, factor = 0.5),\r\n","                                   tf.keras.callbacks.ModelCheckpoint(filepath = model_path, monitor = 'val_acc', save_best_only = True, mode = 'max')])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nc4o1C1A-edp"},"source":["# 모델의 구조를 만들고 load_weights함수를 통해 학습시킨 가중치들을 불러옵니다.\r\n","model0 = my_model()\r\n","model1 = my_model()\r\n","model2 = my_model()\r\n","model3 = my_model()\r\n","model4 = my_model()\r\n","\r\n","model0.load_weights('/content/gdrive/MyDrive/Colab Notebooks/투빅스/densenet0.h5')\r\n","model1.load_weights('/content/gdrive/MyDrive/Colab Notebooks/투빅스/densenet1.h5')\r\n","model2.load_weights('/content/gdrive/MyDrive/Colab Notebooks/투빅스/densenet2.h5')\r\n","model3.load_weights('/content/gdrive/MyDrive/Colab Notebooks/투빅스/densenet3.h5')\r\n","model4.load_weights('/content/gdrive/MyDrive/Colab Notebooks/투빅스/densenet4.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jPoNuv8U_e8i"},"source":["output0 = model0.predict(test)\r\n","output1 = model1.predict(test)\r\n","output2 = model2.predict(test)\r\n","output3 = model3.predict(test)\r\n","output4 = model4.predict(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22_U9rXs_boL"},"source":["# 모델의 예측값을 산술평균하여 앙상블합니다.\r\n","tf_ens_output = (output0 + output1 + output2 + output3 + output4) * 0.2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iATjbLVa_t9E"},"source":["#### 3. densenet + resnet ensemble"]},{"cell_type":"code","metadata":{"id":"mLeVjgMG_bl6"},"source":["# densenet의 결과와 resnet의 결과를 9:1로 앙상블하여 최종 예측값을 만듭니다.\r\n","\r\n","final_output = 0.9 * tf_ens_output + 0.1 * torch_ens_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1sO5yLa_9mh"},"source":["# argmax함수를 사용하여 test image의 category를 예측합니다.\r\n","final_pred = np.argmax(final_output, axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQqhhJmSAMHc"},"source":["sample_submission['Category'] = final_pred\r\n","sample_submission.to_csv(\"/content/gdrive/MyDrive/Colab Notebooks/투빅스/ens.csv\", index = False)"],"execution_count":null,"outputs":[]}]}