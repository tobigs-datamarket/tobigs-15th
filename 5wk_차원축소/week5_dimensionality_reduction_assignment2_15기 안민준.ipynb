{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차원축소 Assignment2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST data에 적용을 해보기\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') #mnist 손글씨 데이터를 불러옵니다\n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정보!\n",
    "- 7만개의 작은 숫자 이미지\n",
    "- 행 열이 반대로 되어있음 -> 전치\n",
    "- grayscale 28x28 pixel = 784 feature\n",
    "- 각 picel은 0~255의 값\n",
    "- label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ] # 데이터의 픽셀 개수 (784개 만큼 반복해서 픽셀 이름을 붙임)\n",
    "df = pd.DataFrame(X,columns=feat_cols) # X를 데이터프레임으로 변환\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (70000, 785)\n"
     ]
    }
   ],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y\n",
    "print('Size of the dataframe: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "69995       0  ...         0         0         0         0         0   \n",
       "69996       0  ...         0         0         0         0         0   \n",
       "69997       0  ...         0         0         0         0         0   \n",
       "69998       0  ...         0         0         0         0         0   \n",
       "69999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783    y  \n",
       "0             0         0         0         0  0.0  \n",
       "1             0         0         0         0  0.0  \n",
       "2             0         0         0         0  0.0  \n",
       "3             0         0         0         0  0.0  \n",
       "4             0         0         0         0  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "69995         0         0         0         0  9.0  \n",
       "69996         0         0         0         0  9.0  \n",
       "69997         0         0         0         0  9.0  \n",
       "69998         0         0         0         0  9.0  \n",
       "69999         0         0         0         0  9.0  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x504 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 형태 시각화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rndperm = np.random.permutation(df.shape[0]) # 전체 개수 중에 일부 출력\n",
    "\n",
    "# Plot the graph\n",
    "plt.gray()\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,15):\n",
    "    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'y'])) )\n",
    "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.452429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.256304</td>\n",
       "      <td>2.783732</td>\n",
       "      <td>1.561822</td>\n",
       "      <td>1.553796</td>\n",
       "      <td>0.320889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.890195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pixel0   pixel1   pixel2   pixel3   pixel4   pixel5   pixel6   pixel7  \\\n",
       "count  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel8   pixel9  ...      pixel775      pixel776      pixel777  \\\n",
       "count  70000.0  70000.0  ...  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.0      0.0  ...      0.099543      0.046629      0.016614   \n",
       "std        0.0      0.0  ...      4.256304      2.783732      1.561822   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    253.000000    253.000000   \n",
       "\n",
       "           pixel778      pixel779  pixel780  pixel781  pixel782  pixel783  \\\n",
       "count  70000.000000  70000.000000   70000.0   70000.0   70000.0   70000.0   \n",
       "mean       0.012957      0.001714       0.0       0.0       0.0       0.0   \n",
       "std        1.553796      0.320889       0.0       0.0       0.0       0.0   \n",
       "min        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "25%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "50%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "75%        0.000000      0.000000       0.0       0.0       0.0       0.0   \n",
       "max      254.000000     62.000000       0.0       0.0       0.0       0.0   \n",
       "\n",
       "                  y  \n",
       "count  70000.000000  \n",
       "mean       4.452429  \n",
       "std        2.890195  \n",
       "min        0.000000  \n",
       "25%        2.000000  \n",
       "50%        4.000000  \n",
       "75%        7.000000  \n",
       "max        9.000000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터의 평균 확인\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max값이 255에 가까운 값이므로 스케일링이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>7.000000e+04</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.744586e-18</td>\n",
       "      <td>4.872293e-18</td>\n",
       "      <td>3.248195e-18</td>\n",
       "      <td>-1.015061e-18</td>\n",
       "      <td>2.233134e-18</td>\n",
       "      <td>2.385393e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>1.000007e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.295091e-02</td>\n",
       "      <td>-2.338733e-02</td>\n",
       "      <td>-1.675050e-02</td>\n",
       "      <td>-1.063784e-02</td>\n",
       "      <td>-8.339086e-03</td>\n",
       "      <td>-5.342334e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.295091e-02</td>\n",
       "      <td>-2.338733e-02</td>\n",
       "      <td>-1.675050e-02</td>\n",
       "      <td>-1.063784e-02</td>\n",
       "      <td>-8.339086e-03</td>\n",
       "      <td>-5.342334e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.295091e-02</td>\n",
       "      <td>-2.338733e-02</td>\n",
       "      <td>-1.675050e-02</td>\n",
       "      <td>-1.063784e-02</td>\n",
       "      <td>-8.339086e-03</td>\n",
       "      <td>-5.342334e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.295091e-02</td>\n",
       "      <td>-2.338733e-02</td>\n",
       "      <td>-1.675050e-02</td>\n",
       "      <td>-1.063784e-02</td>\n",
       "      <td>-8.339086e-03</td>\n",
       "      <td>-5.342334e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.236282e+01</td>\n",
       "      <td>5.965323e+01</td>\n",
       "      <td>9.086908e+01</td>\n",
       "      <td>1.619808e+02</td>\n",
       "      <td>1.634635e+02</td>\n",
       "      <td>1.932091e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5        6        7    \\\n",
       "count  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           8        9    ...           774           775           776  \\\n",
       "count  70000.0  70000.0  ...  7.000000e+04  7.000000e+04  7.000000e+04   \n",
       "mean       0.0      0.0  ... -9.744586e-18  4.872293e-18  3.248195e-18   \n",
       "std        0.0      0.0  ...  1.000007e+00  1.000007e+00  1.000007e+00   \n",
       "min        0.0      0.0  ... -3.295091e-02 -2.338733e-02 -1.675050e-02   \n",
       "25%        0.0      0.0  ... -3.295091e-02 -2.338733e-02 -1.675050e-02   \n",
       "50%        0.0      0.0  ... -3.295091e-02 -2.338733e-02 -1.675050e-02   \n",
       "75%        0.0      0.0  ... -3.295091e-02 -2.338733e-02 -1.675050e-02   \n",
       "max        0.0      0.0  ...  4.236282e+01  5.965323e+01  9.086908e+01   \n",
       "\n",
       "                777           778           779      780      781      782  \\\n",
       "count  7.000000e+04  7.000000e+04  7.000000e+04  70000.0  70000.0  70000.0   \n",
       "mean  -1.015061e-18  2.233134e-18  2.385393e-18      0.0      0.0      0.0   \n",
       "std    1.000007e+00  1.000007e+00  1.000007e+00      0.0      0.0      0.0   \n",
       "min   -1.063784e-02 -8.339086e-03 -5.342334e-03      0.0      0.0      0.0   \n",
       "25%   -1.063784e-02 -8.339086e-03 -5.342334e-03      0.0      0.0      0.0   \n",
       "50%   -1.063784e-02 -8.339086e-03 -5.342334e-03      0.0      0.0      0.0   \n",
       "75%   -1.063784e-02 -8.339086e-03 -5.342334e-03      0.0      0.0      0.0   \n",
       "max    1.619808e+02  1.634635e+02  1.932091e+02      0.0      0.0      0.0   \n",
       "\n",
       "           783  \n",
       "count  70000.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "pd.DataFrame(scaled_X).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 값이 올바르게 정리되지 않은 것 같다.\n",
    "\n",
    "[이 글](https://stackoverflow.com/questions/63746182/correct-way-of-normalizing-and-scaling-the-mnist-dataset) 에 따르면 MNIST 데이터와 같은 이미지의 경우에는 음수 픽셀이 존재하면 안 되므로, StandardScale 보다는 단순히 255로 나누는 스케일링이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = X / 255.0 # 이미지 스케일링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y 데이터는 10개의 라벨로 이루어져 있는데, 데이터 간 잘못된 상관관계를 만들 우려가 있어서 one-hot 인코딩 형태로 변환했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0  1.0  2.0  3.0  4.0  5.0  6.0  7.0  8.0  9.0\n",
       "0    1    0    0    0    0    0    0    0    0    0\n",
       "1    1    0    0    0    0    0    0    0    0    0\n",
       "2    1    0    0    0    0    0    0    0    0    0\n",
       "3    1    0    0    0    0    0    0    0    0    0\n",
       "4    1    0    0    0    0    0    0    0    0    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one_hot_y = pd.get_dummies(df['y'])\n",
    "# one_hot_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train : (56000, 784)\n",
      "shape of X_test : (14000, 784)\n",
      "shape of y_train : (56000, 1)\n",
      "shape of y_test : (14000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of X_train : {X_train.shape}\\nshape of X_test : {X_test.shape}\\nshape of y_train : {y_train.shape}\\nshape of y_test : {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여기서부터는 원본데이터 & PCA 축소 데이터 & LDA 축소 데이터 비교해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 차원축소 기법(PCA와 LDA)을 이용하여 mnist data를 축소시켜주세요\n",
    "\n",
    "pca를 이용할 때는, 주성분 개수를 정하는 과정에 대해 잘 서술해주시면 좋겠죠!<br>\n",
    "강의에서 배웠던 3가지 중 어떤 걸 고려해서 갯수를 정했는지요!!!!<br>\n",
    "scree plot같은거는 직접 그려서 확인해주면 좋겠죠???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추가 : PCA의 고유값 개수\n",
    "\n",
    "강의에서 배웠던 주성분을 정하는 방법은 다음과 같다.\n",
    "- Elbow point method : Factor_number 에 따른 고유값의 크기로 그래프를 그렸을 때 고유값의 크기가 급격히 감소하는 지점 (Elbow Point)에서 선택)\n",
    "- Kaiser's Rule : 고유값이 1이상인 주성분들만 선택\n",
    "- 누적설명률이 70 ~ 80 % 이상인 지점에서 선택\n",
    "\n",
    "누적 설명률이란?\n",
    "- 누적 기여율이라고도 한다.\n",
    "- 전체 고유값 중 해당 고유값이 전체를 얼마나 설명하는지를 나타내는 변수라고 볼 수 있을 것 같다.\n",
    "- 주로 아래와 같은 공식으로 계산된다.\n",
    "![누적 기여율](https://blog.kakaocdn.net/dn/2DViq/btqDrkPgxdK/HDToKix0c8yJgopFjkPBjK/img.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Elbow Point 를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.26354800e+00,  6.49285157e-02,  1.59845569e+00, ...,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00],\n",
       "       [-1.84107409e+00,  2.40213821e+00, -1.39673437e+00, ...,\n",
       "         1.54517593e-17, -8.95520214e-16,  9.99723956e-17],\n",
       "       [-2.69305892e+00, -2.60832456e-01, -8.48167834e-01, ...,\n",
       "        -1.95394493e-15, -2.01273649e-15,  7.56042921e-18],\n",
       "       ...,\n",
       "       [-4.64508520e-01,  2.06200296e+00, -1.61615420e+00, ...,\n",
       "         1.35710925e-18, -3.00348995e-18,  4.53579614e-19],\n",
       "       [ 6.75567609e+00, -2.40366807e+00,  2.26744664e+00, ...,\n",
       "         1.26971051e-17,  1.28687497e-17, -1.54383579e-18],\n",
       "       [ 2.68365562e-01, -2.72796395e-01, -7.63535496e-01, ...,\n",
       "        -5.06258117e-18, -2.52261875e-18, -3.07279670e-18]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=X.shape[1], copy=False)\n",
    "pca_x = pca.fit_transform(X_train)\n",
    "pca_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explained_variance_ 를 사용해 설명 변수(고유값을 확인할 수 있다.)\n",
    "exv = pca.explained_variance_\n",
    "exv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.14506678, 3.77649087, 3.23914747, 2.85546   , 2.57863563])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exv[:5] # 크기순으로 정렬된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Scree plot\")\n",
    "plt.plot(np.arange(exv.shape[0]), exv, marker='o')\n",
    "plt.xlabel(\"Factor Number\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 너무 많아 제대로 확인되지 않는다.\n",
    "확인 결과, Factor Number 가 15이 되기 전에 Elbow point 가 발견되었으므로 그 부분만 따로 표시해 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Scree plot\")\n",
    "plt.plot(np.arange(exv[:20].shape[0]), exv[:20], marker='o') # 80개만 표시\n",
    "plt.xlabel(\"Factor Number\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor Number 가 12가 되는 위치에서 Elbow Point가 관측되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Kaiser's Rule\n",
    "\n",
    "고유값이 1 이상인 데이터만 표시해 보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exv[exv >= 1].shape # 고유값이 1이상인 데이터만 표시 후 길이를 측정해 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12로 나타났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 누적설명률(누적기여율)이 70~80인 지점으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.80, copy=False) # 80% 지점 # n_components 에 실수를 주면 누적설명률을 기준으로 pca를 할 수 있다.\n",
    "pca_x = pca.fit_transform(X_train)\n",
    "exv = pca.explained_variance_\n",
    "exv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.7, copy=False) # 70% 지점\n",
    "pca_x = pca.fit_transform(X_train)\n",
    "exv = pca.explained_variance_\n",
    "exv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "누적설명률을 기준으로 하면 43 ~ 26개의 고유값을 가질 때 누적설명률이 70~80%로 나타났다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 : LDA\n",
    "\n",
    "LDA는 데이터를 특정 축에 projection 한 후 데이터를 가장 잘 구분하는 직선을 찾아낸다.\n",
    "\n",
    "projection 한 데이터의 중심벡터와 분산을 찾아내 중심은 최대, 분산은 최소화 하는 벡터를 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 9)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "lda_X = clf.fit_transform(X_train,y_train.reshape(-1)) # LDA 모듈은 one-hot을 받지 않기 때문에 y에서 y_train에 해당하는 부분만 사용.\n",
    "lda_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23708117, 0.20328823, 0.17798282, 0.10633489, 0.09415639,\n",
       "       0.06896763, 0.04990535, 0.03507761, 0.02720591])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explained_variance_ratio_에 각 변수의 설명력을 구할 수 있다.\n",
    "clf.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shape` 를 통해 확인해 보니 총 9개의 변수로 축소시킨 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 지금까지 배웠던 머신러닝 기법을 이용하여 학습해주세요 (2개이상 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  이때 time stamp를 찍어서 training 시간을 비교하고, test accuracy도 비교해주세요\n",
    "#### (원본 데이터 & PCA 축소 데이터 & LDA 축소 데이터 비교)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linear_model` 의 [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression),\n",
    "`svm`의 [`SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html?highlight=svc#sklearn.svm.SVC),\n",
    "`ensemble`의 [`AdaBoostClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier)\n",
    ", [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
    ", light\n",
    "으로 확인하고, Stacking하여 최종적으로 판별해 보고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42) # warnings 방지\n",
    "svc = SVC(random_state = 42, max_iter=1000)\n",
    "ada = AdaBoostClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "\n",
    "# 모두 기본 파라미터로 학습\n",
    "\n",
    "models = [lr, svc, ada, rf, lgbm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression(), accuracy_score: 0.9234285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LinearSVC(), accuracy_score: 0.9157857142857143\n",
      "model: AdaBoostClassifier(), accuracy_score: 0.7192857142857143\n",
      "model: RandomForestClassifier(), accuracy_score: 0.969\n",
      "model: LGBMClassifier(), accuracy_score: 0.977\n",
      "경과시간 310.9980411529541\n"
     ]
    }
   ],
   "source": [
    "# 원본 데이터로 네 모델 모두 학습 후 예측하는데 걸리는 시간 측정\n",
    "start = time.time()\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train.reshape(-1))\n",
    "    print(f\"model: {model.__class__()}, accuracy_score: {accuracy_score(y_test, model.predict(X_test))}\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"경과시간\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca 변환 (80%로 설명)\n",
    "pca = PCA(n_components=0.80, copy=False)\n",
    "pca_x = pca.fit_transform(X_train)\n",
    "\n",
    "# LDA 변환\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "lda_X = clf.fit_transform(X_train,y_train.reshape(-1)) # LDA 모듈은 one-hot을 받지 않기 때문에 y에서 y_train에 해당하는 부분만 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터에 대한 변환\n",
    "pca_test_X = pca.transform(X_test) # fit 하지않고 transform만 실시함\n",
    "lda_test_X = clf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression(), accuracy_score: 0.905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LinearSVC(), accuracy_score: 0.8936428571428572\n",
      "model: AdaBoostClassifier(), accuracy_score: 0.699\n",
      "model: RandomForestClassifier(), accuracy_score: 0.9528571428571428\n",
      "model: LGBMClassifier(), accuracy_score: 0.9657142857142857\n",
      "경과시간 117.73004984855652\n"
     ]
    }
   ],
   "source": [
    "# pca 된 데이터로 네 모델 모두 학습 후 예측하는데 걸리는 시간 측정\n",
    "start = time.time()\n",
    "\n",
    "for model in models:\n",
    "    model.fit(pca_x, y_train.reshape(-1))\n",
    "    print(f\"model: {model.__class__()}, accuracy_score: {accuracy_score(y_test, model.predict(pca_test_X))}\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"경과시간\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression(), accuracy_score: 0.8160714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LinearSVC(), accuracy_score: 0.8052857142857143\n",
      "model: AdaBoostClassifier(), accuracy_score: 0.7755714285714286\n",
      "model: RandomForestClassifier(), accuracy_score: 0.8482142857142857\n",
      "model: LGBMClassifier(), accuracy_score: 0.8322857142857143\n",
      "경과시간 54.8597617149353\n"
     ]
    }
   ],
   "source": [
    "# lda 된 데이터로 네 모델 모두 학습 후 예측하는데 걸리는 시간 측정\n",
    "start = time.time()\n",
    "\n",
    "for model in models:\n",
    "    model.fit(lda_X, y_train.reshape(-1))\n",
    "    print(f\"model: {model.__class__()}, accuracy_score: {accuracy_score(y_test, model.predict(lda_test_X))}\")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"경과시간\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경과 시간의 경우 LDA > PCA > 변환 없음으로 나타났다. 차원이 축소되어 계산량이 확실히 줄었음을 확인할 수 있다.\n",
    "\n",
    "특히 변환이 없을 때 300초가 걸린 것과 달리, 단순히 차원 축소만 실행했음에도 불구하고 계산 시간이 100초대로 줄어드는 둥 큰 변화를 보였다.\n",
    "\n",
    "LDA 변환에서는 그 특징이 더 크게 나타났는데, 54초로 상당히 빨리 끝난 것을 확인할 수 있다.\n",
    "\n",
    "정확도 면에서도 변환 없음 > PCA > LDA 순이었다.\n",
    "\n",
    "PCA의 경우 설명력이 80% 지점에서 선택한 것으로, 대부분의 설명이 가능해서 차원을 축소하지 않은 데이터와 별 차이가 없었다.\n",
    "\n",
    "LDA의 경우 차원이 낮으므로, 모델이 계산하기 어려웠던 것으로 것으로 추정된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 튜닝\n",
    "\n",
    "위 4가지 모델의 하이퍼파라미터를 튜닝해서 사용한다.\n",
    "\n",
    "로지스틱 회귀 모델은 파라미터가 존재하지 않아 튜닝하지 않겠다.\n",
    "\n",
    "속도가 빠른 `optuna` 모듈을 사용하겠으며, 정확도와 속도를 모두 잡은 PCA된 데이터를 사용하여 튜닝하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna # 속도가 빠른 하이퍼파라미터 튜닝 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 09:00:23,915]\u001b[0m A new study created in memory with name: no-name-a2eb8e94-4e60-4c6c-9e7a-0eab52915fe2\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:01:16,794]\u001b[0m Trial 0 finished with value: 0.9877142857142858 and parameters: {'svc_c': 6.299588390377998}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:02:09,397]\u001b[0m Trial 1 finished with value: 0.9872857142857143 and parameters: {'svc_c': 243.37147977270402}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:15:19,365]\u001b[0m Trial 2 finished with value: 0.7089285714285715 and parameters: {'svc_c': 0.0010695715823228792}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:16:14,667]\u001b[0m Trial 3 finished with value: 0.9832857142857143 and parameters: {'svc_c': 1.025568771230862}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:17:10,386]\u001b[0m Trial 4 finished with value: 0.983 and parameters: {'svc_c': 0.9612417365328193}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:17:56,481]\u001b[0m Trial 5 finished with value: 0.9874285714285714 and parameters: {'svc_c': 46.354420212289064}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:18:44,928]\u001b[0m Trial 6 finished with value: 0.9874285714285714 and parameters: {'svc_c': 4.618088795190436}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:27:37,874]\u001b[0m Trial 7 finished with value: 0.894 and parameters: {'svc_c': 0.0030742877384841217}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:30:07,140]\u001b[0m Trial 8 finished with value: 0.9600714285714286 and parameters: {'svc_c': 0.0524586879279385}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:30:53,483]\u001b[0m Trial 9 finished with value: 0.9872857142857143 and parameters: {'svc_c': 1604.7162301984094}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:33:41,042]\u001b[0m Trial 10 finished with value: 0.9557857142857142 and parameters: {'svc_c': 0.039359777354314854}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:34:28,247]\u001b[0m Trial 11 finished with value: 0.9873571428571428 and parameters: {'svc_c': 73.93475213769062}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:35:15,124]\u001b[0m Trial 12 finished with value: 0.9873571428571428 and parameters: {'svc_c': 25.335080017586556}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:36:01,353]\u001b[0m Trial 13 finished with value: 0.9872857142857143 and parameters: {'svc_c': 2883.769202683468}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:36:48,595]\u001b[0m Trial 14 finished with value: 0.9876428571428572 and parameters: {'svc_c': 9.427658610708331}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:38:29,353]\u001b[0m Trial 15 finished with value: 0.9695 and parameters: {'svc_c': 0.14177871757078855}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:39:17,216]\u001b[0m Trial 16 finished with value: 0.9875 and parameters: {'svc_c': 4.400546961323273}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:40:05,123]\u001b[0m Trial 17 finished with value: 0.9875714285714285 and parameters: {'svc_c': 6.498343668039418}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:40:53,232]\u001b[0m Trial 18 finished with value: 0.9872857142857143 and parameters: {'svc_c': 497.31781065919944}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:42:08,063]\u001b[0m Trial 19 finished with value: 0.9774285714285714 and parameters: {'svc_c': 0.33931190674603157}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:47:26,492]\u001b[0m Trial 20 finished with value: 0.9294285714285714 and parameters: {'svc_c': 0.008680617351269364}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:48:11,182]\u001b[0m Trial 21 finished with value: 0.9876428571428572 and parameters: {'svc_c': 5.234308043808686}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 09:48:55,667]\u001b[0m Trial 22 finished with value: 0.9875714285714285 and parameters: {'svc_c': 12.477429538320203}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:01:44,747]\u001b[0m Trial 23 finished with value: 0.11292857142857143 and parameters: {'svc_c': 0.00014905777894210886}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:02:45,899]\u001b[0m Trial 24 finished with value: 0.985 and parameters: {'svc_c': 1.5136372585402098}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:03:41,070]\u001b[0m Trial 25 finished with value: 0.9872857142857143 and parameters: {'svc_c': 147.7710975249784}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:04:29,467]\u001b[0m Trial 26 finished with value: 0.9875714285714285 and parameters: {'svc_c': 19.550593891324713}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:05:24,898]\u001b[0m Trial 27 finished with value: 0.9856428571428572 and parameters: {'svc_c': 2.1982110513677493}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:06:42,311]\u001b[0m Trial 28 finished with value: 0.9775714285714285 and parameters: {'svc_c': 0.36799599922007953}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:07:38,332]\u001b[0m Trial 29 finished with value: 0.9872857142857143 and parameters: {'svc_c': 475.9268940512148}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:08:33,095]\u001b[0m Trial 30 finished with value: 0.9872857142857143 and parameters: {'svc_c': 135.8157635142525}. Best is trial 0 with value: 0.9877142857142858.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:09:27,364]\u001b[0m Trial 31 finished with value: 0.9877857142857143 and parameters: {'svc_c': 17.17348241388547}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:10:15,425]\u001b[0m Trial 32 finished with value: 0.9875 and parameters: {'svc_c': 13.047503130445058}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:11:03,175]\u001b[0m Trial 33 finished with value: 0.9875 and parameters: {'svc_c': 43.85074296451418}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:12:13,133]\u001b[0m Trial 34 finished with value: 0.9798571428571429 and parameters: {'svc_c': 0.5293825422221282}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:13:03,649]\u001b[0m Trial 35 finished with value: 0.9870714285714286 and parameters: {'svc_c': 2.896231177137577}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:13:53,301]\u001b[0m Trial 36 finished with value: 0.9876428571428572 and parameters: {'svc_c': 9.418485718533992}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:14:52,603]\u001b[0m Trial 37 finished with value: 0.9833571428571428 and parameters: {'svc_c': 1.113396318759455}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:15:40,652]\u001b[0m Trial 38 finished with value: 0.9872857142857143 and parameters: {'svc_c': 380.97440314259893}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:16:28,927]\u001b[0m Trial 39 finished with value: 0.9873571428571428 and parameters: {'svc_c': 64.06951629744894}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:18:40,900]\u001b[0m Trial 40 finished with value: 0.9635 and parameters: {'svc_c': 0.07774784564884174}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:19:31,452]\u001b[0m Trial 41 finished with value: 0.9876428571428572 and parameters: {'svc_c': 10.431199701954938}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:20:23,606]\u001b[0m Trial 42 finished with value: 0.9874285714285714 and parameters: {'svc_c': 3.5314020953526657}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:21:14,644]\u001b[0m Trial 43 finished with value: 0.9872142857142857 and parameters: {'svc_c': 29.33011371856201}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:22:06,478]\u001b[0m Trial 44 finished with value: 0.9875714285714285 and parameters: {'svc_c': 12.801106648346813}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 10:23:15,340]\u001b[0m Trial 45 finished with value: 0.9815714285714285 and parameters: {'svc_c': 0.6589333374538578}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:24:11,043]\u001b[0m Trial 46 finished with value: 0.9872857142857143 and parameters: {'svc_c': 1186.372258249802}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:25:10,209]\u001b[0m Trial 47 finished with value: 0.9872857142857143 and parameters: {'svc_c': 112.17911071043353}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:26:03,958]\u001b[0m Trial 48 finished with value: 0.9873571428571428 and parameters: {'svc_c': 36.05819294177693}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:26:56,549]\u001b[0m Trial 49 finished with value: 0.9875714285714285 and parameters: {'svc_c': 6.670190119058843}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:28:44,843]\u001b[0m Trial 50 finished with value: 0.9708571428571429 and parameters: {'svc_c': 0.1581562042608739}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:29:45,081]\u001b[0m Trial 51 finished with value: 0.9875714285714285 and parameters: {'svc_c': 6.763282721045267}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:30:43,039]\u001b[0m Trial 52 finished with value: 0.9877142857142858 and parameters: {'svc_c': 9.718708293769172}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:31:48,920]\u001b[0m Trial 53 finished with value: 0.9853571428571428 and parameters: {'svc_c': 2.024528040188376}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:32:48,975]\u001b[0m Trial 54 finished with value: 0.9877857142857143 and parameters: {'svc_c': 15.449485546653863}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:33:49,598]\u001b[0m Trial 55 finished with value: 0.9875714285714285 and parameters: {'svc_c': 21.689022494927777}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:34:48,312]\u001b[0m Trial 56 finished with value: 0.9877857142857143 and parameters: {'svc_c': 15.380322599535477}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:35:46,789]\u001b[0m Trial 57 finished with value: 0.9872857142857143 and parameters: {'svc_c': 88.24941434747812}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:36:48,347]\u001b[0m Trial 58 finished with value: 0.9872857142857143 and parameters: {'svc_c': 184.13610261535842}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:37:46,907]\u001b[0m Trial 59 finished with value: 0.9873571428571428 and parameters: {'svc_c': 50.55765188556418}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:38:46,426]\u001b[0m Trial 60 finished with value: 0.9874285714285714 and parameters: {'svc_c': 4.572950941439044}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:39:43,366]\u001b[0m Trial 61 finished with value: 0.9876428571428572 and parameters: {'svc_c': 19.0016899537025}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:40:40,250]\u001b[0m Trial 62 finished with value: 0.9876428571428572 and parameters: {'svc_c': 9.44632367434361}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:41:40,465]\u001b[0m Trial 63 finished with value: 0.9854285714285714 and parameters: {'svc_c': 2.120379356831662}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:42:38,659]\u001b[0m Trial 64 finished with value: 0.9877142857142858 and parameters: {'svc_c': 16.247351734585077}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:43:35,654]\u001b[0m Trial 65 finished with value: 0.9872857142857143 and parameters: {'svc_c': 33.49629837831192}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:44:45,087]\u001b[0m Trial 66 finished with value: 0.9824285714285714 and parameters: {'svc_c': 0.8939885973152074}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:45:41,718]\u001b[0m Trial 67 finished with value: 0.9872857142857143 and parameters: {'svc_c': 7592.457411058756}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:46:38,800]\u001b[0m Trial 68 finished with value: 0.9873571428571428 and parameters: {'svc_c': 60.93591000891608}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:47:35,836]\u001b[0m Trial 69 finished with value: 0.9872857142857143 and parameters: {'svc_c': 249.81899061726534}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:48:33,450]\u001b[0m Trial 70 finished with value: 0.9877142857142858 and parameters: {'svc_c': 17.976350716803992}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:49:30,395]\u001b[0m Trial 71 finished with value: 0.9877142857142858 and parameters: {'svc_c': 16.161013584565477}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:50:28,156]\u001b[0m Trial 72 finished with value: 0.9876428571428572 and parameters: {'svc_c': 18.395452053728842}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:51:26,455]\u001b[0m Trial 73 finished with value: 0.9876428571428572 and parameters: {'svc_c': 5.418526615333313}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:52:26,778]\u001b[0m Trial 74 finished with value: 0.9874285714285714 and parameters: {'svc_c': 3.5216288420722055}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:53:25,147]\u001b[0m Trial 75 finished with value: 0.9876428571428572 and parameters: {'svc_c': 20.418339155323082}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:54:30,173]\u001b[0m Trial 76 finished with value: 0.9847857142857143 and parameters: {'svc_c': 1.4486605063671625}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:55:28,334]\u001b[0m Trial 77 finished with value: 0.9872857142857143 and parameters: {'svc_c': 91.34904614041392}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:56:26,033]\u001b[0m Trial 78 finished with value: 0.9875 and parameters: {'svc_c': 44.87955018941791}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:57:23,980]\u001b[0m Trial 79 finished with value: 0.9877857142857143 and parameters: {'svc_c': 14.604092735366851}. Best is trial 31 with value: 0.9877857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:58:22,830]\u001b[0m Trial 80 finished with value: 0.9878571428571429 and parameters: {'svc_c': 14.971964747211656}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 10:59:21,745]\u001b[0m Trial 81 finished with value: 0.9876428571428572 and parameters: {'svc_c': 13.87870367118222}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:00:19,929]\u001b[0m Trial 82 finished with value: 0.9872142857142857 and parameters: {'svc_c': 27.86671995695595}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:01:18,190]\u001b[0m Trial 83 finished with value: 0.9876428571428572 and parameters: {'svc_c': 7.369976878996764}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:02:18,804]\u001b[0m Trial 84 finished with value: 0.9867142857142858 and parameters: {'svc_c': 2.783024903721453}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:03:16,059]\u001b[0m Trial 85 finished with value: 0.9877857142857143 and parameters: {'svc_c': 9.551227824891638}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:04:15,151]\u001b[0m Trial 86 finished with value: 0.9877142857142858 and parameters: {'svc_c': 16.455266233645894}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:05:15,909]\u001b[0m Trial 87 finished with value: 0.9874285714285714 and parameters: {'svc_c': 4.1092793291455}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:06:15,226]\u001b[0m Trial 88 finished with value: 0.9876428571428572 and parameters: {'svc_c': 8.094386229638545}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:07:12,137]\u001b[0m Trial 89 finished with value: 0.9873571428571428 and parameters: {'svc_c': 67.66380300312859}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 11:08:08,677]\u001b[0m Trial 90 finished with value: 0.9872142857142857 and parameters: {'svc_c': 31.484654408792327}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:09:05,141]\u001b[0m Trial 91 finished with value: 0.9875 and parameters: {'svc_c': 13.00996238553574}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:10:02,278]\u001b[0m Trial 92 finished with value: 0.9877142857142858 and parameters: {'svc_c': 9.68347429801012}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:10:59,288]\u001b[0m Trial 93 finished with value: 0.9873571428571428 and parameters: {'svc_c': 25.32300865454852}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:11:56,886]\u001b[0m Trial 94 finished with value: 0.9876428571428572 and parameters: {'svc_c': 5.507461490668012}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:12:55,710]\u001b[0m Trial 95 finished with value: 0.9872857142857143 and parameters: {'svc_c': 229.87907252610265}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:13:56,431]\u001b[0m Trial 96 finished with value: 0.9875 and parameters: {'svc_c': 44.52575599256567}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:14:53,467]\u001b[0m Trial 97 finished with value: 0.9872857142857143 and parameters: {'svc_c': 117.96459784307632}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:15:52,148]\u001b[0m Trial 98 finished with value: 0.9877142857142858 and parameters: {'svc_c': 16.013520046470205}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:16:49,734]\u001b[0m Trial 99 finished with value: 0.9877142857142858 and parameters: {'svc_c': 9.653822135765534}. Best is trial 80 with value: 0.9878571428571429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial score : 0.9878571428571429\n",
      "Best Params: {'svc_c': 14.971964747211656}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# SVM 모델 튜닝\n",
    "def svc_objective(trial):\n",
    "    \n",
    "    svc_c = trial.suggest_loguniform('svc_c', 1e-4, 1e4)\n",
    "    classifier_obj = SVC(C=svc_c, random_state=42)\n",
    "    \n",
    "    classifier_obj.fit(pca_x, y_train.reshape(-1))\n",
    "    accuracy = accuracy_score(y_test, classifier_obj.predict(pca_test_X))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "svm_study = optuna.create_study(direction='maximize')\n",
    "svm_study.optimize(svc_objective, n_trials=100)\n",
    "print(f\"Best trial score : {svm_study.best_trial.value}\\nBest Params: {svm_study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-01 23:03:11,848]\u001b[0m A new study created in memory with name: no-name-1e9a2577-fc05-4d1e-967c-cc80d39fb8fa\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:03:15,049]\u001b[0m Trial 0 finished with value: 0.199 and parameters: {'n_estimators': 8, 'learning_rate': 0.00017296524855836635}. Best is trial 0 with value: 0.199.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:03:45,046]\u001b[0m Trial 1 finished with value: 0.199 and parameters: {'n_estimators': 82, 'learning_rate': 0.00011987396846828823}. Best is trial 0 with value: 0.199.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:04:17,638]\u001b[0m Trial 2 finished with value: 0.449 and parameters: {'n_estimators': 95, 'learning_rate': 0.006352295165948613}. Best is trial 2 with value: 0.449.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:04:23,272]\u001b[0m Trial 3 finished with value: 0.199 and parameters: {'n_estimators': 16, 'learning_rate': 1.3392632227063425e-05}. Best is trial 2 with value: 0.449.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:04:35,920]\u001b[0m Trial 4 finished with value: 0.7145 and parameters: {'n_estimators': 37, 'learning_rate': 0.8898328602815464}. Best is trial 4 with value: 0.7145.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:04:44,984]\u001b[0m Trial 5 finished with value: 0.5378571428571428 and parameters: {'n_estimators': 25, 'learning_rate': 0.12237462790181906}. Best is trial 4 with value: 0.7145.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:04:50,344]\u001b[0m Trial 6 finished with value: 0.199 and parameters: {'n_estimators': 15, 'learning_rate': 1.727202880298201e-05}. Best is trial 4 with value: 0.7145.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:05:08,860]\u001b[0m Trial 7 finished with value: 0.199 and parameters: {'n_estimators': 46, 'learning_rate': 0.0005204345312844614}. Best is trial 4 with value: 0.7145.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:05:23,622]\u001b[0m Trial 8 finished with value: 0.45964285714285713 and parameters: {'n_estimators': 35, 'learning_rate': 0.02264595316589086}. Best is trial 4 with value: 0.7145.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:05:59,798]\u001b[0m Trial 9 finished with value: 0.28614285714285714 and parameters: {'n_estimators': 89, 'learning_rate': 0.000574153818445862}. Best is trial 4 with value: 0.7145.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:06:26,903]\u001b[0m Trial 10 finished with value: 0.7195714285714285 and parameters: {'n_estimators': 66, 'learning_rate': 0.8361018010180378}. Best is trial 10 with value: 0.7195714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:06:54,404]\u001b[0m Trial 11 finished with value: 0.7291428571428571 and parameters: {'n_estimators': 67, 'learning_rate': 0.8236784493254411}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:07:21,613]\u001b[0m Trial 12 finished with value: 0.7122142857142857 and parameters: {'n_estimators': 67, 'learning_rate': 0.9393055823583691}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:07:47,960]\u001b[0m Trial 13 finished with value: 0.6613571428571429 and parameters: {'n_estimators': 69, 'learning_rate': 0.1553094594349844}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:08:13,166]\u001b[0m Trial 14 finished with value: 0.6612142857142858 and parameters: {'n_estimators': 63, 'learning_rate': 0.1798740991958407}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:08:37,079]\u001b[0m Trial 15 finished with value: 0.716 and parameters: {'n_estimators': 59, 'learning_rate': 0.5478848305730563}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:09:09,010]\u001b[0m Trial 16 finished with value: 0.5302857142857142 and parameters: {'n_estimators': 78, 'learning_rate': 0.04014565524225281}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:09:29,954]\u001b[0m Trial 17 finished with value: 0.4487857142857143 and parameters: {'n_estimators': 52, 'learning_rate': 0.01141186830731265}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:09:59,882]\u001b[0m Trial 18 finished with value: 0.7147857142857142 and parameters: {'n_estimators': 76, 'learning_rate': 0.26895182586088734}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:10:17,528]\u001b[0m Trial 19 finished with value: 0.5125714285714286 and parameters: {'n_estimators': 50, 'learning_rate': 0.05630395190637367}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:10:58,974]\u001b[0m Trial 20 finished with value: 0.2950714285714286 and parameters: {'n_estimators': 99, 'learning_rate': 0.0029990852054627122}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:11:24,585]\u001b[0m Trial 21 finished with value: 0.7189285714285715 and parameters: {'n_estimators': 60, 'learning_rate': 0.9463511877536442}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:11:49,284]\u001b[0m Trial 22 finished with value: 0.6956428571428571 and parameters: {'n_estimators': 58, 'learning_rate': 0.924596399122461}. Best is trial 11 with value: 0.7291428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:12:16,348]\u001b[0m Trial 23 finished with value: 0.7392857142857143 and parameters: {'n_estimators': 70, 'learning_rate': 0.42441278451293407}. Best is trial 23 with value: 0.7392857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:12:51,607]\u001b[0m Trial 24 finished with value: 0.74 and parameters: {'n_estimators': 87, 'learning_rate': 0.38656918022322423}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:13:27,609]\u001b[0m Trial 25 finished with value: 0.7281428571428571 and parameters: {'n_estimators': 85, 'learning_rate': 0.36900072741585427}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:14:06,316]\u001b[0m Trial 26 finished with value: 0.6396428571428572 and parameters: {'n_estimators': 93, 'learning_rate': 0.08759149255475113}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:14:36,815]\u001b[0m Trial 27 finished with value: 0.7382857142857143 and parameters: {'n_estimators': 75, 'learning_rate': 0.3483443255867987}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:15:05,985]\u001b[0m Trial 28 finished with value: 0.5078571428571429 and parameters: {'n_estimators': 73, 'learning_rate': 0.024845050783134835}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:15:44,881]\u001b[0m Trial 29 finished with value: 0.7378571428571429 and parameters: {'n_estimators': 100, 'learning_rate': 0.35126199506859}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:16:19,527]\u001b[0m Trial 30 finished with value: 0.618 and parameters: {'n_estimators': 84, 'learning_rate': 0.08100971136235309}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:16:58,458]\u001b[0m Trial 31 finished with value: 0.7188571428571429 and parameters: {'n_estimators': 98, 'learning_rate': 0.25237535342985873}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:17:32,889]\u001b[0m Trial 32 finished with value: 0.7304285714285714 and parameters: {'n_estimators': 88, 'learning_rate': 0.38618651938762516}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:17:58,973]\u001b[0m Trial 33 finished with value: 0.7332142857142857 and parameters: {'n_estimators': 75, 'learning_rate': 0.35910676489756266}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:18:31,468]\u001b[0m Trial 34 finished with value: 0.7110714285714286 and parameters: {'n_estimators': 93, 'learning_rate': 0.16945063085299722}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:19:01,682]\u001b[0m Trial 35 finished with value: 0.5390714285714285 and parameters: {'n_estimators': 80, 'learning_rate': 0.03712405578548816}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:19:40,804]\u001b[0m Trial 36 finished with value: 0.45207142857142857 and parameters: {'n_estimators': 90, 'learning_rate': 0.007741606882086364}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:20:19,289]\u001b[0m Trial 37 finished with value: 0.2938571428571429 and parameters: {'n_estimators': 100, 'learning_rate': 0.0024654408352977586}. Best is trial 24 with value: 0.74.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:20:52,543]\u001b[0m Trial 38 finished with value: 0.7405714285714285 and parameters: {'n_estimators': 83, 'learning_rate': 0.4839843135335063}. Best is trial 38 with value: 0.7405714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:21:23,155]\u001b[0m Trial 39 finished with value: 0.6280714285714286 and parameters: {'n_estimators': 72, 'learning_rate': 0.09605169486967727}. Best is trial 38 with value: 0.7405714285714285.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-01 23:21:55,082]\u001b[0m Trial 40 finished with value: 0.199 and parameters: {'n_estimators': 79, 'learning_rate': 3.5184464819589076e-05}. Best is trial 38 with value: 0.7405714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:22:26,932]\u001b[0m Trial 41 finished with value: 0.7425714285714285 and parameters: {'n_estimators': 85, 'learning_rate': 0.5273834026144911}. Best is trial 41 with value: 0.7425714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:22:59,210]\u001b[0m Trial 42 finished with value: 0.7416428571428572 and parameters: {'n_estimators': 83, 'learning_rate': 0.584827782063583}. Best is trial 41 with value: 0.7425714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:23:30,553]\u001b[0m Trial 43 finished with value: 0.742 and parameters: {'n_estimators': 83, 'learning_rate': 0.5832757192922455}. Best is trial 41 with value: 0.7425714285714285.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:24:03,252]\u001b[0m Trial 44 finished with value: 0.7438571428571429 and parameters: {'n_estimators': 83, 'learning_rate': 0.6522425727490734}. Best is trial 44 with value: 0.7438571428571429.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:24:36,379]\u001b[0m Trial 45 finished with value: 0.7530714285714286 and parameters: {'n_estimators': 83, 'learning_rate': 0.6469735482670431}. Best is trial 45 with value: 0.7530714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:24:37,697]\u001b[0m Trial 46 finished with value: 0.34935714285714287 and parameters: {'n_estimators': 3, 'learning_rate': 0.612066314007874}. Best is trial 45 with value: 0.7530714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:25:12,731]\u001b[0m Trial 47 finished with value: 0.7051428571428572 and parameters: {'n_estimators': 92, 'learning_rate': 0.9435189318635678}. Best is trial 45 with value: 0.7530714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:25:44,840]\u001b[0m Trial 48 finished with value: 0.6991428571428572 and parameters: {'n_estimators': 82, 'learning_rate': 0.18781606167665713}. Best is trial 45 with value: 0.7530714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:26:21,464]\u001b[0m Trial 49 finished with value: 0.6855714285714286 and parameters: {'n_estimators': 95, 'learning_rate': 0.12928380199234316}. Best is trial 45 with value: 0.7530714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:26:56,617]\u001b[0m Trial 50 finished with value: 0.7421428571428571 and parameters: {'n_estimators': 87, 'learning_rate': 0.6527753111217403}. Best is trial 45 with value: 0.7530714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:27:29,967]\u001b[0m Trial 51 finished with value: 0.7547857142857143 and parameters: {'n_estimators': 87, 'learning_rate': 0.642030769563898}. Best is trial 51 with value: 0.7547857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:28:04,529]\u001b[0m Trial 52 finished with value: 0.7242857142857143 and parameters: {'n_estimators': 88, 'learning_rate': 0.6868841125619051}. Best is trial 51 with value: 0.7547857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:28:35,127]\u001b[0m Trial 53 finished with value: 0.7123571428571429 and parameters: {'n_estimators': 79, 'learning_rate': 0.9994813711921928}. Best is trial 51 with value: 0.7547857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:29:12,725]\u001b[0m Trial 54 finished with value: 0.7260714285714286 and parameters: {'n_estimators': 94, 'learning_rate': 0.24572542611930354}. Best is trial 51 with value: 0.7547857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:29:51,877]\u001b[0m Trial 55 finished with value: 0.7631428571428571 and parameters: {'n_estimators': 96, 'learning_rate': 0.6610069832017895}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:30:30,144]\u001b[0m Trial 56 finished with value: 0.28614285714285714 and parameters: {'n_estimators': 97, 'learning_rate': 0.0007039878878034373}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:31:05,543]\u001b[0m Trial 57 finished with value: 0.7174285714285714 and parameters: {'n_estimators': 90, 'learning_rate': 0.22446773981976104}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:31:15,619]\u001b[0m Trial 58 finished with value: 0.656 and parameters: {'n_estimators': 28, 'learning_rate': 0.9880303432922672}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:31:50,536]\u001b[0m Trial 59 finished with value: 0.6067142857142858 and parameters: {'n_estimators': 86, 'learning_rate': 0.06069112103118307}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:32:17,079]\u001b[0m Trial 60 finished with value: 0.6364285714285715 and parameters: {'n_estimators': 64, 'learning_rate': 0.1248952360371429}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:32:49,818]\u001b[0m Trial 61 finished with value: 0.7451428571428571 and parameters: {'n_estimators': 81, 'learning_rate': 0.6344304873996783}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:33:23,418]\u001b[0m Trial 62 finished with value: 0.7494285714285714 and parameters: {'n_estimators': 78, 'learning_rate': 0.6628849502713807}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:33:54,856]\u001b[0m Trial 63 finished with value: 0.7 and parameters: {'n_estimators': 78, 'learning_rate': 0.9933756683023671}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:34:22,530]\u001b[0m Trial 64 finished with value: 0.726 and parameters: {'n_estimators': 69, 'learning_rate': 0.2815265843443538}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:34:59,386]\u001b[0m Trial 65 finished with value: 0.7278571428571429 and parameters: {'n_estimators': 91, 'learning_rate': 0.48130064649478793}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:35:30,729]\u001b[0m Trial 66 finished with value: 0.7299285714285715 and parameters: {'n_estimators': 76, 'learning_rate': 0.6845446795796448}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:36:09,695]\u001b[0m Trial 67 finished with value: 0.7116428571428571 and parameters: {'n_estimators': 96, 'learning_rate': 0.17970815028905518}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:36:26,983]\u001b[0m Trial 68 finished with value: 0.6848571428571428 and parameters: {'n_estimators': 41, 'learning_rate': 0.271597685727358}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:37:01,489]\u001b[0m Trial 69 finished with value: 0.7439285714285714 and parameters: {'n_estimators': 80, 'learning_rate': 0.46810375084305944}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:37:30,792]\u001b[0m Trial 70 finished with value: 0.737 and parameters: {'n_estimators': 74, 'learning_rate': 0.833759595372396}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:38:04,262]\u001b[0m Trial 71 finished with value: 0.7286428571428571 and parameters: {'n_estimators': 80, 'learning_rate': 0.293858951898596}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:38:38,372]\u001b[0m Trial 72 finished with value: 0.7450714285714286 and parameters: {'n_estimators': 85, 'learning_rate': 0.46847918532352484}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:39:06,779]\u001b[0m Trial 73 finished with value: 0.7287857142857143 and parameters: {'n_estimators': 72, 'learning_rate': 0.4439084451091206}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:39:37,375]\u001b[0m Trial 74 finished with value: 0.7454285714285714 and parameters: {'n_estimators': 77, 'learning_rate': 0.7146210734368257}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:40:03,789]\u001b[0m Trial 75 finished with value: 0.7187857142857143 and parameters: {'n_estimators': 70, 'learning_rate': 0.9706338431421033}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:40:35,835]\u001b[0m Trial 76 finished with value: 0.7411428571428571 and parameters: {'n_estimators': 80, 'learning_rate': 0.41500081951712753}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:41:07,457]\u001b[0m Trial 77 finished with value: 0.6986428571428571 and parameters: {'n_estimators': 77, 'learning_rate': 0.2024290386354883}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:41:42,920]\u001b[0m Trial 78 finished with value: 0.7228571428571429 and parameters: {'n_estimators': 89, 'learning_rate': 0.7606599727641375}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-01 23:42:08,566]\u001b[0m Trial 79 finished with value: 0.6584285714285715 and parameters: {'n_estimators': 66, 'learning_rate': 0.1516895911947742}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:42:40,951]\u001b[0m Trial 80 finished with value: 0.7298571428571429 and parameters: {'n_estimators': 85, 'learning_rate': 0.31149756675806334}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:43:09,747]\u001b[0m Trial 81 finished with value: 0.7532142857142857 and parameters: {'n_estimators': 81, 'learning_rate': 0.5071401052088045}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:43:38,586]\u001b[0m Trial 82 finished with value: 0.748 and parameters: {'n_estimators': 80, 'learning_rate': 0.5018429603625932}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:44:08,833]\u001b[0m Trial 83 finished with value: 0.7380714285714286 and parameters: {'n_estimators': 82, 'learning_rate': 0.719072605657323}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:44:29,823]\u001b[0m Trial 84 finished with value: 0.6192142857142857 and parameters: {'n_estimators': 55, 'learning_rate': 0.10128577383896066}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:45:04,901]\u001b[0m Trial 85 finished with value: 0.7391428571428571 and parameters: {'n_estimators': 87, 'learning_rate': 0.3635881139413078}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:45:34,448]\u001b[0m Trial 86 finished with value: 0.7482142857142857 and parameters: {'n_estimators': 77, 'learning_rate': 0.5191837009814317}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:46:01,462]\u001b[0m Trial 87 finished with value: 0.199 and parameters: {'n_estimators': 72, 'learning_rate': 6.65949405200235e-05}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:46:31,839]\u001b[0m Trial 88 finished with value: 0.7340714285714286 and parameters: {'n_estimators': 76, 'learning_rate': 0.5525800888949688}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:47:06,839]\u001b[0m Trial 89 finished with value: 0.7417142857142857 and parameters: {'n_estimators': 91, 'learning_rate': 0.8281861355246365}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:47:37,115]\u001b[0m Trial 90 finished with value: 0.7024285714285714 and parameters: {'n_estimators': 68, 'learning_rate': 0.21766084157640575}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:48:11,781]\u001b[0m Trial 91 finished with value: 0.7480714285714286 and parameters: {'n_estimators': 81, 'learning_rate': 0.5262916142225733}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:48:45,871]\u001b[0m Trial 92 finished with value: 0.7294285714285714 and parameters: {'n_estimators': 81, 'learning_rate': 0.31908910497415827}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:49:13,662]\u001b[0m Trial 93 finished with value: 0.7326428571428572 and parameters: {'n_estimators': 74, 'learning_rate': 0.7480294066920515}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:49:43,479]\u001b[0m Trial 94 finished with value: 0.7308571428571429 and parameters: {'n_estimators': 78, 'learning_rate': 0.48917501965825294}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:50:15,337]\u001b[0m Trial 95 finished with value: 0.7392142857142857 and parameters: {'n_estimators': 77, 'learning_rate': 0.3773046914283868}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:50:42,891]\u001b[0m Trial 96 finished with value: 0.28914285714285715 and parameters: {'n_estimators': 71, 'learning_rate': 0.00156948220218195}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:51:12,999]\u001b[0m Trial 97 finished with value: 0.7547142857142857 and parameters: {'n_estimators': 82, 'learning_rate': 0.5642233020592963}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:51:43,742]\u001b[0m Trial 98 finished with value: 0.7150714285714286 and parameters: {'n_estimators': 84, 'learning_rate': 0.9751005025617097}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-01 23:52:17,306]\u001b[0m Trial 99 finished with value: 0.6902857142857143 and parameters: {'n_estimators': 89, 'learning_rate': 0.14482256811591626}. Best is trial 55 with value: 0.7631428571428571.\u001b[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Study' object has no attribute 'best_trial_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d34b7e3f695b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mada_study\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mada_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best trial score : {ada_study.best_trial_value}\\nBest Params: {ada_study.best_trial.params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Study' object has no attribute 'best_trial_value'"
     ]
    }
   ],
   "source": [
    "# AdaBoost 모델 튜닝\n",
    "def ada_objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-5, 1)\n",
    "    \n",
    "    classifier_obj = AdaBoostClassifier(n_estimators=n_estimators, learning_rate = lr, random_state=42)\n",
    "    \n",
    "    classifier_obj.fit(pca_x, y_train.reshape(-1))\n",
    "    accuracy = accuracy_score(y_test, classifier_obj.predict(pca_test_X))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "ada_study = optuna.create_study(direction='maximize')\n",
    "ada_study.optimize(ada_objective, n_trials=100)\n",
    "print(f\"Best trial score : {ada_study.best_trial_value}\\nBest Params: {ada_study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial score : 0.7631428571428571\n",
      "Best Params: {'n_estimators': 96, 'learning_rate': 0.6610069832017895}\n"
     ]
    }
   ],
   "source": [
    "# 실수로 오류가 나서 아래 작성\n",
    "print(f\"Best trial score : {ada_study.best_trial.value}\\nBest Params: {ada_study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:07:16,046]\u001b[0m A new study created in memory with name: no-name-56b38755-a97e-418d-a5aa-cbe2696f34af\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:07:56,222]\u001b[0m Trial 0 finished with value: 0.9522857142857143 and parameters: {'n_estimators': 96, 'max_depth': 67}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:07:57,272]\u001b[0m Trial 1 finished with value: 0.6097857142857143 and parameters: {'n_estimators': 15, 'max_depth': 2}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:08:02,234]\u001b[0m Trial 2 finished with value: 0.9304285714285714 and parameters: {'n_estimators': 12, 'max_depth': 43}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:08:09,710]\u001b[0m Trial 3 finished with value: 0.9024285714285715 and parameters: {'n_estimators': 29, 'max_depth': 10}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:08:46,283]\u001b[0m Trial 4 finished with value: 0.9520714285714286 and parameters: {'n_estimators': 87, 'max_depth': 47}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:09:06,328]\u001b[0m Trial 5 finished with value: 0.9514285714285714 and parameters: {'n_estimators': 48, 'max_depth': 31}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:09:42,021]\u001b[0m Trial 6 finished with value: 0.9522142857142857 and parameters: {'n_estimators': 84, 'max_depth': 96}. Best is trial 0 with value: 0.9522857142857143.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:10:08,594]\u001b[0m Trial 7 finished with value: 0.9524285714285714 and parameters: {'n_estimators': 63, 'max_depth': 86}. Best is trial 7 with value: 0.9524285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:10:11,974]\u001b[0m Trial 8 finished with value: 0.9164285714285715 and parameters: {'n_estimators': 8, 'max_depth': 37}. Best is trial 7 with value: 0.9524285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:10:26,758]\u001b[0m Trial 9 finished with value: 0.95 and parameters: {'n_estimators': 35, 'max_depth': 27}. Best is trial 7 with value: 0.9524285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:10:56,875]\u001b[0m Trial 10 finished with value: 0.9522857142857143 and parameters: {'n_estimators': 69, 'max_depth': 95}. Best is trial 7 with value: 0.9524285714285714.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:11:39,862]\u001b[0m Trial 11 finished with value: 0.9526428571428571 and parameters: {'n_estimators': 99, 'max_depth': 72}. Best is trial 11 with value: 0.9526428571428571.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:12:08,768]\u001b[0m Trial 12 finished with value: 0.9527142857142857 and parameters: {'n_estimators': 66, 'max_depth': 74}. Best is trial 12 with value: 0.9527142857142857.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:12:50,983]\u001b[0m Trial 13 finished with value: 0.9527857142857142 and parameters: {'n_estimators': 98, 'max_depth': 70}. Best is trial 13 with value: 0.9527857142857142.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:13:21,567]\u001b[0m Trial 14 finished with value: 0.9520714285714286 and parameters: {'n_estimators': 71, 'max_depth': 65}. Best is trial 13 with value: 0.9527857142857142.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:13:42,776]\u001b[0m Trial 15 finished with value: 0.9517857142857142 and parameters: {'n_estimators': 49, 'max_depth': 81}. Best is trial 13 with value: 0.9527857142857142.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:14:17,268]\u001b[0m Trial 16 finished with value: 0.9523571428571429 and parameters: {'n_estimators': 80, 'max_depth': 57}. Best is trial 13 with value: 0.9527857142857142.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:14:43,603]\u001b[0m Trial 17 finished with value: 0.9523571428571429 and parameters: {'n_estimators': 62, 'max_depth': 81}. Best is trial 13 with value: 0.9527857142857142.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:15:24,885]\u001b[0m Trial 18 finished with value: 0.9527857142857142 and parameters: {'n_estimators': 95, 'max_depth': 57}. Best is trial 13 with value: 0.9527857142857142.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:16:07,451]\u001b[0m Trial 19 finished with value: 0.9528571428571428 and parameters: {'n_estimators': 100, 'max_depth': 55}. Best is trial 19 with value: 0.9528571428571428.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:16:46,418]\u001b[0m Trial 20 finished with value: 0.9535714285714286 and parameters: {'n_estimators': 99, 'max_depth': 19}. Best is trial 20 with value: 0.9535714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:17:25,312]\u001b[0m Trial 21 finished with value: 0.9524285714285714 and parameters: {'n_estimators': 92, 'max_depth': 57}. Best is trial 20 with value: 0.9535714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:18:04,586]\u001b[0m Trial 22 finished with value: 0.9538571428571428 and parameters: {'n_estimators': 100, 'max_depth': 19}. Best is trial 22 with value: 0.9538571428571428.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:18:34,273]\u001b[0m Trial 23 finished with value: 0.9502857142857143 and parameters: {'n_estimators': 78, 'max_depth': 18}. Best is trial 22 with value: 0.9538571428571428.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:19:07,614]\u001b[0m Trial 24 finished with value: 0.9477142857142857 and parameters: {'n_estimators': 88, 'max_depth': 17}. Best is trial 22 with value: 0.9538571428571428.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:19:17,136]\u001b[0m Trial 25 finished with value: 0.7812142857142857 and parameters: {'n_estimators': 78, 'max_depth': 4}. Best is trial 22 with value: 0.9538571428571428.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:19:57,976]\u001b[0m Trial 26 finished with value: 0.9539285714285715 and parameters: {'n_estimators': 98, 'max_depth': 24}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:20:35,054]\u001b[0m Trial 27 finished with value: 0.9532857142857143 and parameters: {'n_estimators': 90, 'max_depth': 25}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:20:54,772]\u001b[0m Trial 28 finished with value: 0.9365714285714286 and parameters: {'n_estimators': 57, 'max_depth': 13}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:21:37,141]\u001b[0m Trial 29 finished with value: 0.9536428571428571 and parameters: {'n_estimators': 100, 'max_depth': 34}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:22:20,875]\u001b[0m Trial 30 finished with value: 0.9536428571428571 and parameters: {'n_estimators': 100, 'max_depth': 34}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:23:04,353]\u001b[0m Trial 31 finished with value: 0.9532142857142857 and parameters: {'n_estimators': 100, 'max_depth': 37}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:23:43,018]\u001b[0m Trial 32 finished with value: 0.9528571428571428 and parameters: {'n_estimators': 93, 'max_depth': 34}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:24:17,353]\u001b[0m Trial 33 finished with value: 0.9523571428571429 and parameters: {'n_estimators': 81, 'max_depth': 41}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:24:55,690]\u001b[0m Trial 34 finished with value: 0.9532857142857143 and parameters: {'n_estimators': 93, 'max_depth': 26}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:25:08,572]\u001b[0m Trial 35 finished with value: 0.8438571428571429 and parameters: {'n_estimators': 74, 'max_depth': 6}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:25:44,556]\u001b[0m Trial 36 finished with value: 0.9519285714285715 and parameters: {'n_estimators': 86, 'max_depth': 46}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:25:55,786]\u001b[0m Trial 37 finished with value: 0.9449285714285715 and parameters: {'n_estimators': 27, 'max_depth': 22}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:26:31,946]\u001b[0m Trial 38 finished with value: 0.9532857142857143 and parameters: {'n_estimators': 86, 'max_depth': 31}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:26:54,988]\u001b[0m Trial 39 finished with value: 0.9 and parameters: {'n_estimators': 95, 'max_depth': 9}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:26:56,395]\u001b[0m Trial 40 finished with value: 0.5355714285714286 and parameters: {'n_estimators': 37, 'max_depth': 1}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:27:35,037]\u001b[0m Trial 41 finished with value: 0.9535714285714286 and parameters: {'n_estimators': 99, 'max_depth': 19}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:28:06,869]\u001b[0m Trial 42 finished with value: 0.9377857142857143 and parameters: {'n_estimators': 100, 'max_depth': 13}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:28:44,278]\u001b[0m Trial 43 finished with value: 0.9523571428571429 and parameters: {'n_estimators': 89, 'max_depth': 40}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:29:26,518]\u001b[0m Trial 44 finished with value: 0.9537857142857142 and parameters: {'n_estimators': 100, 'max_depth': 30}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:30:01,200]\u001b[0m Trial 45 finished with value: 0.9527142857142857 and parameters: {'n_estimators': 83, 'max_depth': 32}. Best is trial 26 with value: 0.9539285714285715.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:30:40,852]\u001b[0m Trial 46 finished with value: 0.9545 and parameters: {'n_estimators': 95, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:31:19,534]\u001b[0m Trial 47 finished with value: 0.9535714285714286 and parameters: {'n_estimators': 94, 'max_depth': 26}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:32:00,003]\u001b[0m Trial 48 finished with value: 0.9525 and parameters: {'n_estimators': 90, 'max_depth': 49}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:32:31,273]\u001b[0m Trial 49 finished with value: 0.9535 and parameters: {'n_estimators': 74, 'max_depth': 30}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:33:10,837]\u001b[0m Trial 50 finished with value: 0.9535 and parameters: {'n_estimators': 96, 'max_depth': 23}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:33:52,536]\u001b[0m Trial 51 finished with value: 0.9536428571428571 and parameters: {'n_estimators': 100, 'max_depth': 35}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:34:33,134]\u001b[0m Trial 52 finished with value: 0.9523571428571429 and parameters: {'n_estimators': 96, 'max_depth': 45}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:35:08,611]\u001b[0m Trial 53 finished with value: 0.9522142857142857 and parameters: {'n_estimators': 84, 'max_depth': 39}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:35:46,421]\u001b[0m Trial 54 finished with value: 0.9538571428571428 and parameters: {'n_estimators': 91, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:36:23,566]\u001b[0m Trial 55 finished with value: 0.9531428571428572 and parameters: {'n_estimators': 90, 'max_depth': 29}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:36:55,585]\u001b[0m Trial 56 finished with value: 0.9438571428571428 and parameters: {'n_estimators': 95, 'max_depth': 14}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:37:30,663]\u001b[0m Trial 57 finished with value: 0.954 and parameters: {'n_estimators': 87, 'max_depth': 23}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:37:31,100]\u001b[0m Trial 58 finished with value: 0.7564285714285715 and parameters: {'n_estimators': 1, 'max_depth': 22}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:37:51,180]\u001b[0m Trial 59 finished with value: 0.9116428571428571 and parameters: {'n_estimators': 76, 'max_depth': 10}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:38:07,114]\u001b[0m Trial 60 finished with value: 0.9442142857142857 and parameters: {'n_estimators': 43, 'max_depth': 16}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:38:43,977]\u001b[0m Trial 61 finished with value: 0.9542857142857143 and parameters: {'n_estimators': 87, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:39:17,044]\u001b[0m Trial 62 finished with value: 0.9533571428571429 and parameters: {'n_estimators': 84, 'max_depth': 21}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:39:49,423]\u001b[0m Trial 63 finished with value: 0.9543571428571429 and parameters: {'n_estimators': 81, 'max_depth': 27}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:40:25,001]\u001b[0m Trial 64 finished with value: 0.9543571428571429 and parameters: {'n_estimators': 81, 'max_depth': 27}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:40:51,551]\u001b[0m Trial 65 finished with value: 0.9532142857142857 and parameters: {'n_estimators': 66, 'max_depth': 25}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:41:23,893]\u001b[0m Trial 66 finished with value: 0.9542857142857143 and parameters: {'n_estimators': 79, 'max_depth': 27}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:41:55,298]\u001b[0m Trial 67 finished with value: 0.9517857142857142 and parameters: {'n_estimators': 78, 'max_depth': 24}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:42:24,327]\u001b[0m Trial 68 finished with value: 0.9518571428571428 and parameters: {'n_estimators': 69, 'max_depth': 37}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:42:54,179]\u001b[0m Trial 69 finished with value: 0.9527142857142857 and parameters: {'n_estimators': 72, 'max_depth': 42}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:43:23,189]\u001b[0m Trial 70 finished with value: 0.9488571428571428 and parameters: {'n_estimators': 81, 'max_depth': 16}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:43:59,474]\u001b[0m Trial 71 finished with value: 0.9542857142857143 and parameters: {'n_estimators': 87, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:44:33,146]\u001b[0m Trial 72 finished with value: 0.9532142857142857 and parameters: {'n_estimators': 86, 'max_depth': 20}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:45:06,322]\u001b[0m Trial 73 finished with value: 0.9538571428571428 and parameters: {'n_estimators': 81, 'max_depth': 26}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:45:31,034]\u001b[0m Trial 74 finished with value: 0.9522857142857143 and parameters: {'n_estimators': 60, 'max_depth': 32}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:46:07,597]\u001b[0m Trial 75 finished with value: 0.9537142857142857 and parameters: {'n_estimators': 87, 'max_depth': 36}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:46:40,120]\u001b[0m Trial 76 finished with value: 0.9538571428571428 and parameters: {'n_estimators': 79, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:47:11,911]\u001b[0m Trial 77 finished with value: 0.9536428571428571 and parameters: {'n_estimators': 76, 'max_depth': 23}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:47:50,070]\u001b[0m Trial 78 finished with value: 0.9524285714285714 and parameters: {'n_estimators': 92, 'max_depth': 32}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:48:12,100]\u001b[0m Trial 79 finished with value: 0.9123571428571429 and parameters: {'n_estimators': 83, 'max_depth': 10}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:48:48,319]\u001b[0m Trial 80 finished with value: 0.9541428571428572 and parameters: {'n_estimators': 88, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:49:23,846]\u001b[0m Trial 81 finished with value: 0.9545 and parameters: {'n_estimators': 86, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:50:00,223]\u001b[0m Trial 82 finished with value: 0.9541428571428572 and parameters: {'n_estimators': 88, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:50:34,883]\u001b[0m Trial 83 finished with value: 0.9540714285714286 and parameters: {'n_estimators': 84, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:51:11,488]\u001b[0m Trial 84 finished with value: 0.9529285714285715 and parameters: {'n_estimators': 88, 'max_depth': 38}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:51:42,822]\u001b[0m Trial 85 finished with value: 0.9528571428571428 and parameters: {'n_estimators': 75, 'max_depth': 34}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:52:15,844]\u001b[0m Trial 86 finished with value: 0.9528571428571428 and parameters: {'n_estimators': 80, 'max_depth': 31}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:52:49,836]\u001b[0m Trial 87 finished with value: 0.9527857142857142 and parameters: {'n_estimators': 82, 'max_depth': 53}. Best is trial 46 with value: 0.9545.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:53:24,782]\u001b[0m Trial 88 finished with value: 0.953 and parameters: {'n_estimators': 92, 'max_depth': 19}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:53:54,220]\u001b[0m Trial 89 finished with value: 0.9539285714285715 and parameters: {'n_estimators': 72, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:54:30,432]\u001b[0m Trial 90 finished with value: 0.9532142857142857 and parameters: {'n_estimators': 89, 'max_depth': 26}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:55:05,365]\u001b[0m Trial 91 finished with value: 0.9527142857142857 and parameters: {'n_estimators': 85, 'max_depth': 30}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:55:37,809]\u001b[0m Trial 92 finished with value: 0.9530714285714286 and parameters: {'n_estimators': 78, 'max_depth': 33}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:56:17,258]\u001b[0m Trial 93 finished with value: 0.9538571428571428 and parameters: {'n_estimators': 97, 'max_depth': 28}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:56:50,154]\u001b[0m Trial 94 finished with value: 0.9533571428571429 and parameters: {'n_estimators': 84, 'max_depth': 21}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:57:26,542]\u001b[0m Trial 95 finished with value: 0.952 and parameters: {'n_estimators': 88, 'max_depth': 100}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:58:05,900]\u001b[0m Trial 96 finished with value: 0.9527142857142857 and parameters: {'n_estimators': 94, 'max_depth': 63}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:58:43,582]\u001b[0m Trial 97 finished with value: 0.953 and parameters: {'n_estimators': 90, 'max_depth': 44}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:59:18,681]\u001b[0m Trial 98 finished with value: 0.9529285714285715 and parameters: {'n_estimators': 85, 'max_depth': 35}. Best is trial 46 with value: 0.9545.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 00:59:49,234]\u001b[0m Trial 99 finished with value: 0.9481428571428572 and parameters: {'n_estimators': 82, 'max_depth': 17}. Best is trial 46 with value: 0.9545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial score : 0.9545\n",
      "Best Params: {'n_estimators': 95, 'max_depth': 28}\n"
     ]
    }
   ],
   "source": [
    "# RandomForest 모델 튜닝\n",
    "def rf_objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "    depth = trial.suggest_int('max_depth', 1, 100)\n",
    "    \n",
    "    classifier_obj = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth, random_state=42)\n",
    "    \n",
    "    classifier_obj.fit(pca_x, y_train.reshape(-1))\n",
    "    accuracy = accuracy_score(y_test, classifier_obj.predict(pca_test_X))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "rf_study = optuna.create_study(direction='maximize')\n",
    "rf_study.optimize(rf_objective, n_trials=100)\n",
    "print(f\"Best trial score : {rf_study.best_trial.value}\\nBest Params: {rf_study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:59:49,244]\u001b[0m A new study created in memory with name: no-name-c91ac2e7-0e8c-4226-abb8-bf6fc5c892bc\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:59:50,752]\u001b[0m Trial 0 finished with value: 0.4198571428571429 and parameters: {'n_estimators': 28, 'depth': 17, 'learning_rate': 0.0005273079747056392}. Best is trial 0 with value: 0.4198571428571429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:59:54,486]\u001b[0m Trial 1 finished with value: 0.9525714285714286 and parameters: {'n_estimators': 66, 'depth': 26, 'learning_rate': 0.07867314747781834}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:59:55,942]\u001b[0m Trial 2 finished with value: 0.11292857142857143 and parameters: {'n_estimators': 27, 'depth': 39, 'learning_rate': 2.559209848515842e-05}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 00:59:59,233]\u001b[0m Trial 3 finished with value: 0.11292857142857143 and parameters: {'n_estimators': 62, 'depth': 43, 'learning_rate': 0.00010640815219976832}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:01,175]\u001b[0m Trial 4 finished with value: 0.11292857142857143 and parameters: {'n_estimators': 40, 'depth': 75, 'learning_rate': 5.41196624270502e-05}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:04,117]\u001b[0m Trial 5 finished with value: 0.4067142857142857 and parameters: {'n_estimators': 68, 'depth': 39, 'learning_rate': 0.8318663675970789}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:08,028]\u001b[0m Trial 6 finished with value: 0.9122857142857143 and parameters: {'n_estimators': 76, 'depth': 18, 'learning_rate': 0.02053768000144246}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:10,500]\u001b[0m Trial 7 finished with value: 0.11292857142857143 and parameters: {'n_estimators': 58, 'depth': 71, 'learning_rate': 2.3821538003624142e-05}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 01:00:13,853]\u001b[0m Trial 8 finished with value: 0.8919285714285714 and parameters: {'n_estimators': 97, 'depth': 4, 'learning_rate': 0.023196507609275177}. Best is trial 1 with value: 0.9525714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:17,521]\u001b[0m Trial 9 finished with value: 0.9675 and parameters: {'n_estimators': 65, 'depth': 69, 'learning_rate': 0.3107884171606716}. Best is trial 9 with value: 0.9675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:21,864]\u001b[0m Trial 10 finished with value: 0.7551428571428571 and parameters: {'n_estimators': 96, 'depth': 100, 'learning_rate': 0.4809650422568205}. Best is trial 9 with value: 0.9675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:26,440]\u001b[0m Trial 11 finished with value: 0.9612857142857143 and parameters: {'n_estimators': 83, 'depth': 66, 'learning_rate': 0.09367589667591919}. Best is trial 9 with value: 0.9675.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:31,446]\u001b[0m Trial 12 finished with value: 0.9687857142857143 and parameters: {'n_estimators': 84, 'depth': 69, 'learning_rate': 0.1943371799057531}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:35,605]\u001b[0m Trial 13 finished with value: 0.8684285714285714 and parameters: {'n_estimators': 86, 'depth': 95, 'learning_rate': 0.0036991313994321575}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:35,938]\u001b[0m Trial 14 finished with value: 0.7907142857142857 and parameters: {'n_estimators': 1, 'depth': 83, 'learning_rate': 0.28611167441665897}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:38,020]\u001b[0m Trial 15 finished with value: 0.2792142857142857 and parameters: {'n_estimators': 48, 'depth': 56, 'learning_rate': 0.9740274018325301}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:42,744]\u001b[0m Trial 16 finished with value: 0.8723571428571428 and parameters: {'n_estimators': 100, 'depth': 60, 'learning_rate': 0.003748599271711882}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:47,076]\u001b[0m Trial 17 finished with value: 0.965 and parameters: {'n_estimators': 75, 'depth': 84, 'learning_rate': 0.1362534009498021}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:51,614]\u001b[0m Trial 18 finished with value: 0.9157857142857143 and parameters: {'n_estimators': 88, 'depth': 84, 'learning_rate': 0.01952143347898838}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:53,928]\u001b[0m Trial 19 finished with value: 0.6707142857142857 and parameters: {'n_estimators': 52, 'depth': 52, 'learning_rate': 0.0004467010515217121}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:00:58,437]\u001b[0m Trial 20 finished with value: 0.9436428571428571 and parameters: {'n_estimators': 76, 'depth': 64, 'learning_rate': 0.046391312953608724}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:02,963]\u001b[0m Trial 21 finished with value: 0.9683571428571428 and parameters: {'n_estimators': 74, 'depth': 89, 'learning_rate': 0.2334563682255144}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:07,045]\u001b[0m Trial 22 finished with value: 0.9659285714285715 and parameters: {'n_estimators': 71, 'depth': 92, 'learning_rate': 0.19782238362123544}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:10,229]\u001b[0m Trial 23 finished with value: 0.819 and parameters: {'n_estimators': 85, 'depth': 76, 'learning_rate': 0.5140103707087532}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:13,079]\u001b[0m Trial 24 finished with value: 0.8815 and parameters: {'n_estimators': 55, 'depth': 90, 'learning_rate': 0.010357949922466221}. Best is trial 12 with value: 0.9687857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:18,404]\u001b[0m Trial 25 finished with value: 0.9703571428571428 and parameters: {'n_estimators': 91, 'depth': 71, 'learning_rate': 0.2698089915882204}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:24,019]\u001b[0m Trial 26 finished with value: 0.9511428571428572 and parameters: {'n_estimators': 100, 'depth': 79, 'learning_rate': 0.04745933891767861}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:27,059]\u001b[0m Trial 27 finished with value: 0.157 and parameters: {'n_estimators': 90, 'depth': 99, 'learning_rate': 0.8119692342156406}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:31,373]\u001b[0m Trial 28 finished with value: 0.9657857142857142 and parameters: {'n_estimators': 80, 'depth': 50, 'learning_rate': 0.1483923177331262}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:35,682]\u001b[0m Trial 29 finished with value: 0.8212142857142857 and parameters: {'n_estimators': 90, 'depth': 88, 'learning_rate': 0.0010850968301211014}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:40,699]\u001b[0m Trial 30 finished with value: 0.9566428571428571 and parameters: {'n_estimators': 92, 'depth': 74, 'learning_rate': 0.06376141277992002}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:43,484]\u001b[0m Trial 31 finished with value: 0.8672142857142857 and parameters: {'n_estimators': 63, 'depth': 67, 'learning_rate': 0.3397687325743653}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:47,685]\u001b[0m Trial 32 finished with value: 0.9677142857142857 and parameters: {'n_estimators': 71, 'depth': 60, 'learning_rate': 0.23219782136725112}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:51,776]\u001b[0m Trial 33 finished with value: 0.9645 and parameters: {'n_estimators': 79, 'depth': 61, 'learning_rate': 0.12704521888596457}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:55,472]\u001b[0m Trial 34 finished with value: 0.8872142857142857 and parameters: {'n_estimators': 72, 'depth': 47, 'learning_rate': 0.010020968436897303}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:01:57,131]\u001b[0m Trial 35 finished with value: 0.8345714285714285 and parameters: {'n_estimators': 36, 'depth': 30, 'learning_rate': 0.6289841954564741}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:01,935]\u001b[0m Trial 36 finished with value: 0.9686428571428571 and parameters: {'n_estimators': 82, 'depth': 56, 'learning_rate': 0.21939166699046306}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:07,031]\u001b[0m Trial 37 finished with value: 0.9497142857142857 and parameters: {'n_estimators': 94, 'depth': 40, 'learning_rate': 0.0467917158926355}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:07,448]\u001b[0m Trial 38 finished with value: 0.8583571428571428 and parameters: {'n_estimators': 6, 'depth': 31, 'learning_rate': 0.9634622294752128}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:12,344]\u001b[0m Trial 39 finished with value: 0.9604285714285714 and parameters: {'n_estimators': 82, 'depth': 79, 'learning_rate': 0.0876879074389012}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:15,841]\u001b[0m Trial 40 finished with value: 0.9175 and parameters: {'n_estimators': 60, 'depth': 54, 'learning_rate': 0.030945179893474756}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:19,783]\u001b[0m Trial 41 finished with value: 0.9666428571428571 and parameters: {'n_estimators': 69, 'depth': 60, 'learning_rate': 0.1840929377801536}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:23,245]\u001b[0m Trial 42 finished with value: 0.8882142857142857 and parameters: {'n_estimators': 77, 'depth': 45, 'learning_rate': 0.27672867160569625}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:26,434]\u001b[0m Trial 43 finished with value: 0.8096428571428571 and parameters: {'n_estimators': 68, 'depth': 73, 'learning_rate': 0.520012736610167}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:31,133]\u001b[0m Trial 44 finished with value: 0.9603571428571429 and parameters: {'n_estimators': 84, 'depth': 69, 'learning_rate': 0.08487169745010716}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:35,468]\u001b[0m Trial 45 finished with value: 0.9686428571428571 and parameters: {'n_estimators': 74, 'depth': 58, 'learning_rate': 0.2885269367387618}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:39,351]\u001b[0m Trial 46 finished with value: 0.7571428571428571 and parameters: {'n_estimators': 96, 'depth': 55, 'learning_rate': 0.3700418366340329}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:41,660]\u001b[0m Trial 47 finished with value: 0.41114285714285714 and parameters: {'n_estimators': 45, 'depth': 48, 'learning_rate': 0.9461232399854873}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:45,147]\u001b[0m Trial 48 finished with value: 0.9611428571428572 and parameters: {'n_estimators': 65, 'depth': 65, 'learning_rate': 0.11553227781840703}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:49,330]\u001b[0m Trial 49 finished with value: 0.8912142857142857 and parameters: {'n_estimators': 82, 'depth': 71, 'learning_rate': 0.01030679472956937}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:52,399]\u001b[0m Trial 50 finished with value: 0.8313571428571429 and parameters: {'n_estimators': 74, 'depth': 57, 'learning_rate': 0.448365414462051}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:02:57,427]\u001b[0m Trial 51 finished with value: 0.9703571428571428 and parameters: {'n_estimators': 87, 'depth': 61, 'learning_rate': 0.2354189402181028}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:02,537]\u001b[0m Trial 52 finished with value: 0.969 and parameters: {'n_estimators': 87, 'depth': 64, 'learning_rate': 0.1592013396441074}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:06,633]\u001b[0m Trial 53 finished with value: 0.11292857142857143 and parameters: {'n_estimators': 88, 'depth': 63, 'learning_rate': 1.3829056552129393e-05}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:11,835]\u001b[0m Trial 54 finished with value: 0.9596428571428571 and parameters: {'n_estimators': 99, 'depth': 57, 'learning_rate': 0.06795651127769356}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:16,635]\u001b[0m Trial 55 finished with value: 0.9696428571428571 and parameters: {'n_estimators': 92, 'depth': 68, 'learning_rate': 0.18860290990420517}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:21,983]\u001b[0m Trial 56 finished with value: 0.9317142857142857 and parameters: {'n_estimators': 92, 'depth': 78, 'learning_rate': 0.028617015296404282}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:26,661]\u001b[0m Trial 57 finished with value: 0.9682857142857143 and parameters: {'n_estimators': 86, 'depth': 69, 'learning_rate': 0.15684377725508603}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:29,999]\u001b[0m Trial 58 finished with value: 0.5151428571428571 and parameters: {'n_estimators': 96, 'depth': 67, 'learning_rate': 0.7851744228666482}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:34,476]\u001b[0m Trial 59 finished with value: 0.9097857142857143 and parameters: {'n_estimators': 88, 'depth': 82, 'learning_rate': 0.017256805102054636}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 01:03:37,166]\u001b[0m Trial 60 finished with value: 0.16307142857142856 and parameters: {'n_estimators': 100, 'depth': 4, 'learning_rate': 9.955948864905275e-05}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:40,801]\u001b[0m Trial 61 finished with value: 0.8724285714285714 and parameters: {'n_estimators': 78, 'depth': 51, 'learning_rate': 0.3010407356037059}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:46,072]\u001b[0m Trial 62 finished with value: 0.965 and parameters: {'n_estimators': 92, 'depth': 63, 'learning_rate': 0.1052245100828065}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:51,017]\u001b[0m Trial 63 finished with value: 0.9682857142857143 and parameters: {'n_estimators': 81, 'depth': 72, 'learning_rate': 0.18877959409872963}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:54,801]\u001b[0m Trial 64 finished with value: 0.7552142857142857 and parameters: {'n_estimators': 85, 'depth': 59, 'learning_rate': 0.41753780747153496}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:03:58,422]\u001b[0m Trial 65 finished with value: 0.6806428571428571 and parameters: {'n_estimators': 89, 'depth': 53, 'learning_rate': 0.5796598207822101}. Best is trial 25 with value: 0.9703571428571428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:03,879]\u001b[0m Trial 66 finished with value: 0.9707857142857143 and parameters: {'n_estimators': 94, 'depth': 76, 'learning_rate': 0.24875604547116803}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:08,702]\u001b[0m Trial 67 finished with value: 0.9528571428571428 and parameters: {'n_estimators': 93, 'depth': 75, 'learning_rate': 0.05341324663019943}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:14,071]\u001b[0m Trial 68 finished with value: 0.9672857142857143 and parameters: {'n_estimators': 97, 'depth': 69, 'learning_rate': 0.13712407143555497}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:15,566]\u001b[0m Trial 69 finished with value: 0.9477142857142857 and parameters: {'n_estimators': 20, 'depth': 81, 'learning_rate': 0.23846462390512208}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:19,006]\u001b[0m Trial 70 finished with value: 0.7399285714285714 and parameters: {'n_estimators': 85, 'depth': 87, 'learning_rate': 0.630072848200977}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:22,647]\u001b[0m Trial 71 finished with value: 0.8475714285714285 and parameters: {'n_estimators': 80, 'depth': 64, 'learning_rate': 0.33210009058730455}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:28,027]\u001b[0m Trial 72 finished with value: 0.97 and parameters: {'n_estimators': 94, 'depth': 58, 'learning_rate': 0.1897641198068159}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:33,285]\u001b[0m Trial 73 finished with value: 0.9610714285714286 and parameters: {'n_estimators': 90, 'depth': 67, 'learning_rate': 0.0825095967479456}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:38,599]\u001b[0m Trial 74 finished with value: 0.9685714285714285 and parameters: {'n_estimators': 94, 'depth': 76, 'learning_rate': 0.17641641613604278}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:43,761]\u001b[0m Trial 75 finished with value: 0.9435714285714286 and parameters: {'n_estimators': 100, 'depth': 71, 'learning_rate': 0.03638183137561185}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:48,682]\u001b[0m Trial 76 finished with value: 0.9652857142857143 and parameters: {'n_estimators': 88, 'depth': 61, 'learning_rate': 0.1107132417184424}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:52,731]\u001b[0m Trial 77 finished with value: 0.8276428571428571 and parameters: {'n_estimators': 95, 'depth': 9, 'learning_rate': 0.37597298775004917}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:04:57,874]\u001b[0m Trial 78 finished with value: 0.9695714285714285 and parameters: {'n_estimators': 91, 'depth': 63, 'learning_rate': 0.255875567077411}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:03,271]\u001b[0m Trial 79 finished with value: 0.9589285714285715 and parameters: {'n_estimators': 98, 'depth': 63, 'learning_rate': 0.06593452767865222}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:08,256]\u001b[0m Trial 80 finished with value: 0.9682142857142857 and parameters: {'n_estimators': 91, 'depth': 76, 'learning_rate': 0.15218772684261275}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:13,090]\u001b[0m Trial 81 finished with value: 0.9697857142857143 and parameters: {'n_estimators': 84, 'depth': 66, 'learning_rate': 0.21348872964989726}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:18,425]\u001b[0m Trial 82 finished with value: 0.9703571428571428 and parameters: {'n_estimators': 87, 'depth': 66, 'learning_rate': 0.2388004183843006}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:23,552]\u001b[0m Trial 83 finished with value: 0.9691428571428572 and parameters: {'n_estimators': 87, 'depth': 67, 'learning_rate': 0.22822733116650268}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:27,304]\u001b[0m Trial 84 finished with value: 0.31957142857142856 and parameters: {'n_estimators': 94, 'depth': 68, 'learning_rate': 0.7185167579137463}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:32,297]\u001b[0m Trial 85 finished with value: 0.9686428571428571 and parameters: {'n_estimators': 84, 'depth': 73, 'learning_rate': 0.2582139421802137}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:37,577]\u001b[0m Trial 86 finished with value: 0.9705 and parameters: {'n_estimators': 90, 'depth': 66, 'learning_rate': 0.22099086320081246}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:41,777]\u001b[0m Trial 87 finished with value: 0.7983571428571429 and parameters: {'n_estimators': 91, 'depth': 61, 'learning_rate': 0.5098277294899826}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:46,339]\u001b[0m Trial 88 finished with value: 0.7997857142857143 and parameters: {'n_estimators': 97, 'depth': 71, 'learning_rate': 0.4350310258786542}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:51,644]\u001b[0m Trial 89 finished with value: 0.9644285714285714 and parameters: {'n_estimators': 94, 'depth': 78, 'learning_rate': 0.1000686736804121}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:05:55,754]\u001b[0m Trial 90 finished with value: 0.7911428571428571 and parameters: {'n_estimators': 90, 'depth': 62, 'learning_rate': 0.0006845621120492268}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:00,865]\u001b[0m Trial 91 finished with value: 0.9707142857142858 and parameters: {'n_estimators': 87, 'depth': 66, 'learning_rate': 0.2354593559143295}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:04,310]\u001b[0m Trial 92 finished with value: 0.8298571428571428 and parameters: {'n_estimators': 83, 'depth': 65, 'learning_rate': 0.32030981177117873}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:09,193]\u001b[0m Trial 93 finished with value: 0.9685714285714285 and parameters: {'n_estimators': 86, 'depth': 58, 'learning_rate': 0.19708695670279186}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:13,898]\u001b[0m Trial 94 finished with value: 0.9637142857142857 and parameters: {'n_estimators': 79, 'depth': 55, 'learning_rate': 0.12389158803440438}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:19,314]\u001b[0m Trial 95 finished with value: 0.9704285714285714 and parameters: {'n_estimators': 98, 'depth': 66, 'learning_rate': 0.25887852421515983}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:23,560]\u001b[0m Trial 96 finished with value: 0.8093571428571429 and parameters: {'n_estimators': 98, 'depth': 66, 'learning_rate': 0.4049547238138512}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:29,180]\u001b[0m Trial 97 finished with value: 0.9703571428571428 and parameters: {'n_estimators': 100, 'depth': 74, 'learning_rate': 0.18577688361858866}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:31,616]\u001b[0m Trial 98 finished with value: 0.19092857142857142 and parameters: {'n_estimators': 100, 'depth': 74, 'learning_rate': 0.9538980849765596}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 01:06:36,778]\u001b[0m Trial 99 finished with value: 0.9683571428571428 and parameters: {'n_estimators': 96, 'depth': 70, 'learning_rate': 0.1349887774820813}. Best is trial 66 with value: 0.9707857142857143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial score : 0.9707857142857143\n",
      "Best Params: {'n_estimators': 94, 'depth': 76, 'learning_rate': 0.24875604547116803}\n"
     ]
    }
   ],
   "source": [
    "# LGBM 모델 튜닝\n",
    "def lgbm_objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "    depth = trial.suggest_int('depth', 1, 100)\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-5, 1)\n",
    "    \n",
    "    classifier_obj = LGBMClassifier(n_estimators=n_estimators, max_depth=depth, learning_rate = lr, random_state=42)\n",
    "    \n",
    "    classifier_obj.fit(pca_x, y_train.reshape(-1))\n",
    "    accuracy = accuracy_score(y_test, classifier_obj.predict(pca_test_X))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(lgbm_objective, n_trials=100)\n",
    "print(f\"Best trial score : {lgbm_study.best_trial.value}\\nBest Params: {lgbm_study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "튜닝 결과 정확도는 다음과 같았다.\n",
    "- SVM : 0.9878571428571429\n",
    "- AdaBoost : 0.7631428571428571\n",
    "- Random Forest : 0.9545\n",
    "- LGBM : 0.9707857142857143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Stacking\n",
    "\n",
    "튜닝 결과 LGBM 모델의 정확도가 97% 로 상당히 높은 정확도이지만\n",
    "\n",
    "Stacking 기법을 사용해 정확도를 조금 더 향상시킬 수 있는지 알아보려 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train : (56000, 784)\n",
      "shape of X_test : (14000, 784)\n",
      "shape of y_train : (56000, 1)\n",
      "shape of y_test : (14000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 shape 출력\n",
    "print(f\"shape of X_train : {X_train.shape}\\nshape of X_test : {X_test.shape}\\nshape of y_train : {y_train.shape}\\nshape of y_test : {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking 에 사용하기 위해 train 데이터를 다시 나눠야 한다.\n",
    "# validation 과 test의 크기를 같게 하기 위해 train데이터를 3, validation을 1로 분할한다.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train : (42000, 784)\n",
      "shape of X_val : (14000, 784)\n",
      "shape of y_train : (42000, 1)\n",
      "shape of y_val : (14000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 현재 shape 출력\n",
    "print(f\"shape of X_train : {X_train.shape}\\nshape of X_val : {X_val.shape}\\nshape of y_train : {y_train.shape}\\nshape of y_val : {y_val.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vecstack import stacking # stacking 을 해 주는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [10]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [4]\n",
      "\n",
      "model  0:     [LogisticRegression]\n",
      "    fold  0:  [0.91607143]\n",
      "    fold  1:  [0.91678571]\n",
      "    fold  2:  [0.91478571]\n",
      "    ----\n",
      "    MEAN:     [0.91588095] + [0.00082753]\n",
      "    FULL:     [0.91588095]\n",
      "\n",
      "model  1:     [SVC]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.97928571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.97957143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.97900000]\n",
      "    ----\n",
      "    MEAN:     [0.97928571] + [0.00023328]\n",
      "    FULL:     [0.97928571]\n",
      "\n",
      "model  2:     [AdaBoostClassifier]\n",
      "    fold  0:  [0.76485714]\n",
      "    fold  1:  [0.76900000]\n",
      "    fold  2:  [0.75921429]\n",
      "    ----\n",
      "    MEAN:     [0.76435714] + [0.00401062]\n",
      "    FULL:     [0.76435714]\n",
      "\n",
      "model  3:     [RandomForestClassifier]\n",
      "    fold  0:  [0.96200000]\n",
      "    fold  1:  [0.96150000]\n",
      "    fold  2:  [0.96078571]\n",
      "    ----\n",
      "    MEAN:     [0.96142857] + [0.00049830]\n",
      "    FULL:     [0.96142857]\n",
      "\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델들 목록\n",
    "lr = LogisticRegression(max_iter=5000, random_state=42)\n",
    "svc = SVC(random_state = 42, C= 14.971964747211656, max_iter=1000)\n",
    "ada = AdaBoostClassifier(random_state=42, n_estimators = 96, learning_rate= 0.6610069832017895)\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators= 95, max_depth= 28)\n",
    "lgbm = LGBMClassifier(random_state=42, n_estimators= 94, max_depth= 76, learning_rate= 0.24875604547116803)\n",
    "\n",
    "models = [lr, svc, ada, rf] # 4개 모델을 Stacking\n",
    "\n",
    "# 최종 판독기\n",
    "predModel = lgbm\n",
    "\n",
    "\n",
    "# Stacking 모델 생성\n",
    "s_train, s_test = stacking(\n",
    "    models, \n",
    "    X_train, y_train, X_val, \n",
    "    regression=False, \n",
    "    n_folds=3,\n",
    "    random_state = None,\n",
    "    verbose=2,\n",
    "    metric= accuracy_score\n",
    "    )\n",
    "\n",
    "predModel.fit(s_train, y_train) # 2차 예측모델 학습\n",
    "\n",
    "prediction = predModel.predict(s_test) # 2번째 모델로 최종 결과값 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy_score: {accuracy_score(y_val, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking 을 실시하여 정확도를 확인해 본 결과 0.98의 정확도를 보였다.\n",
    "\n",
    "lgbm을 stacking 된 데이터에 다시 튜닝해서 결과를 조금 더 향상시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 11:42:53,114]\u001b[0m A new study created in memory with name: no-name-e97ebd90-7f25-4f40-9e16-9b88f8725b26\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:04,153]\u001b[0m Trial 0 finished with value: 0.8876428571428572 and parameters: {'n_estimators': 38, 'depth': 75, 'leaves': 38989, 'learning_rate': 0.0005832256736678494}. Best is trial 0 with value: 0.8876428571428572.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:07,748]\u001b[0m Trial 1 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 11, 'depth': 48, 'leaves': 54784, 'learning_rate': 0.01781553514487793}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:12,419]\u001b[0m Trial 2 finished with value: 0.978 and parameters: {'n_estimators': 19, 'depth': 15, 'leaves': 97360, 'learning_rate': 0.0015441322217617844}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:18,803]\u001b[0m Trial 3 finished with value: 0.9806428571428571 and parameters: {'n_estimators': 33, 'depth': 55, 'leaves': 28953, 'learning_rate': 0.09846202869500548}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:27,206]\u001b[0m Trial 4 finished with value: 0.9797857142857143 and parameters: {'n_estimators': 17, 'depth': 98, 'leaves': 66324, 'learning_rate': 0.46930826610408616}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:36,364]\u001b[0m Trial 5 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 53, 'depth': 42, 'leaves': 22081, 'learning_rate': 0.005443850395430765}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:43:55,792]\u001b[0m Trial 6 finished with value: 0.9798571428571429 and parameters: {'n_estimators': 27, 'depth': 87, 'leaves': 84398, 'learning_rate': 0.001299159655048955}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:44:01,655]\u001b[0m Trial 7 finished with value: 0.981 and parameters: {'n_estimators': 24, 'depth': 24, 'leaves': 39781, 'learning_rate': 0.04766877227133641}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:44:31,695]\u001b[0m Trial 8 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 49, 'depth': 93, 'leaves': 73150, 'learning_rate': 0.011821636744217776}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:44:37,310]\u001b[0m Trial 9 finished with value: 0.1105 and parameters: {'n_estimators': 59, 'depth': 82, 'leaves': 2858, 'learning_rate': 2.47931009597742e-05}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:45:17,247]\u001b[0m Trial 10 finished with value: 0.1105 and parameters: {'n_estimators': 90, 'depth': 57, 'leaves': 55942, 'learning_rate': 5.078142982719738e-05}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:45:17,378]\u001b[0m Trial 11 finished with value: 0.8761428571428571 and parameters: {'n_estimators': 1, 'depth': 34, 'leaves': 7887, 'learning_rate': 0.015844644395899336}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:45:26,692]\u001b[0m Trial 12 finished with value: 0.98 and parameters: {'n_estimators': 72, 'depth': 36, 'leaves': 20213, 'learning_rate': 0.39686321206846187}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:45:26,758]\u001b[0m Trial 13 finished with value: 0.1105 and parameters: {'n_estimators': 1, 'depth': 1, 'leaves': 48473, 'learning_rate': 0.00017750808411948692}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:45:37,341]\u001b[0m Trial 14 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 69, 'depth': 66, 'leaves': 20544, 'learning_rate': 0.0071106201036990925}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:46:00,500]\u001b[0m Trial 15 finished with value: 0.981 and parameters: {'n_estimators': 48, 'depth': 40, 'leaves': 57601, 'learning_rate': 0.04913237570808895}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:46:29,779]\u001b[0m Trial 16 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 98, 'depth': 47, 'leaves': 37935, 'learning_rate': 0.003792143748235569}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:47:07,575]\u001b[0m Trial 17 finished with value: 0.9809285714285715 and parameters: {'n_estimators': 74, 'depth': 68, 'leaves': 71579, 'learning_rate': 0.010195532264294451}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:47:15,303]\u001b[0m Trial 18 finished with value: 0.9809285714285715 and parameters: {'n_estimators': 11, 'depth': 93, 'leaves': 80126, 'learning_rate': 0.19322710076911775}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:47:18,861]\u001b[0m Trial 19 finished with value: 0.8668571428571429 and parameters: {'n_estimators': 40, 'depth': 20, 'leaves': 16522, 'learning_rate': 0.00039445870879049443}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:47:19,305]\u001b[0m Trial 20 finished with value: 0.9808571428571429 and parameters: {'n_estimators': 60, 'depth': 4, 'leaves': 29865, 'learning_rate': 0.03907711791240529}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:47:41,053]\u001b[0m Trial 21 finished with value: 0.9809285714285715 and parameters: {'n_estimators': 49, 'depth': 47, 'leaves': 67067, 'learning_rate': 0.016458382465463307}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:48:04,479]\u001b[0m Trial 22 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 59, 'depth': 29, 'leaves': 82746, 'learning_rate': 0.0028028085536935597}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:48:59,158]\u001b[0m Trial 23 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 75, 'depth': 65, 'leaves': 98160, 'learning_rate': 0.0036988180244578745}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:49:49,838]\u001b[0m Trial 24 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 78, 'depth': 65, 'leaves': 99146, 'learning_rate': 0.001583688058412984}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:50:35,553]\u001b[0m Trial 25 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 87, 'depth': 57, 'leaves': 89981, 'learning_rate': 0.0010022648605653185}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:51:27,637]\u001b[0m Trial 26 finished with value: 0.8767142857142857 and parameters: {'n_estimators': 86, 'depth': 57, 'leaves': 90496, 'learning_rate': 0.00019512739883621917}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:51:48,525]\u001b[0m Trial 27 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 94, 'depth': 48, 'leaves': 41319, 'learning_rate': 0.003101972873744911}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:52:09,343]\u001b[0m Trial 28 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 99, 'depth': 76, 'leaves': 42034, 'learning_rate': 0.004950407138354271}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:52:51,686]\u001b[0m Trial 29 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 83, 'depth': 68, 'leaves': 91503, 'learning_rate': 0.0008019334252628491}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:52:55,423]\u001b[0m Trial 30 finished with value: 0.978 and parameters: {'n_estimators': 68, 'depth': 78, 'leaves': 9951, 'learning_rate': 0.0004292825724563485}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:53:25,857]\u001b[0m Trial 31 finished with value: 0.9807142857142858 and parameters: {'n_estimators': 97, 'depth': 29, 'leaves': 57411, 'learning_rate': 0.028866927994179097}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:53:42,684]\u001b[0m Trial 32 finished with value: 0.981 and parameters: {'n_estimators': 80, 'depth': 71, 'leaves': 48188, 'learning_rate': 0.013411445110178928}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:53:58,587]\u001b[0m Trial 33 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 99, 'depth': 75, 'leaves': 33486, 'learning_rate': 0.0006494537837449103}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 11:54:17,338]\u001b[0m Trial 34 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 95, 'depth': 50, 'leaves': 39802, 'learning_rate': 0.0026731088112382966}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:54:21,437]\u001b[0m Trial 35 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 65, 'depth': 13, 'leaves': 24909, 'learning_rate': 0.002336098033403173}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:54:23,129]\u001b[0m Trial 36 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 63, 'depth': 9, 'leaves': 32486, 'learning_rate': 0.007136876160250207}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:54:24,771]\u001b[0m Trial 37 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 57, 'depth': 10, 'leaves': 30756, 'learning_rate': 0.00883546134804558}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:54:25,872]\u001b[0m Trial 38 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 63, 'depth': 8, 'leaves': 32654, 'learning_rate': 0.005042450633513668}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:54:33,200]\u001b[0m Trial 39 finished with value: 0.9799285714285715 and parameters: {'n_estimators': 71, 'depth': 62, 'leaves': 15878, 'learning_rate': 0.09030189489615828}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:54:49,992]\u001b[0m Trial 40 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 92, 'depth': 52, 'leaves': 45955, 'learning_rate': 0.0021203239683247562}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:55:16,600]\u001b[0m Trial 41 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 91, 'depth': 44, 'leaves': 51675, 'learning_rate': 0.0010927071553595827}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:55:34,864]\u001b[0m Trial 42 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 91, 'depth': 39, 'leaves': 45301, 'learning_rate': 0.001910193535584012}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:55:57,445]\u001b[0m Trial 43 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 88, 'depth': 41, 'leaves': 53048, 'learning_rate': 0.0009506346185351654}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:56:30,229]\u001b[0m Trial 44 finished with value: 0.4818571428571429 and parameters: {'n_estimators': 85, 'depth': 29, 'leaves': 61577, 'learning_rate': 0.00015468114849069147}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:57:30,739]\u001b[0m Trial 45 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 98, 'depth': 76, 'leaves': 91148, 'learning_rate': 0.0005049370040402919}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:58:27,129]\u001b[0m Trial 46 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 82, 'depth': 60, 'leaves': 92149, 'learning_rate': 0.000773059657257732}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 11:59:18,622]\u001b[0m Trial 47 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 78, 'depth': 84, 'leaves': 95022, 'learning_rate': 0.004262420732942968}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:00:13,448]\u001b[0m Trial 48 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 77, 'depth': 54, 'leaves': 99277, 'learning_rate': 0.0015622810138791277}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:00:32,094]\u001b[0m Trial 49 finished with value: 0.8876428571428572 and parameters: {'n_estimators': 79, 'depth': 86, 'leaves': 41601, 'learning_rate': 0.00028170036668261945}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:00:37,826]\u001b[0m Trial 50 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 64, 'depth': 11, 'leaves': 28921, 'learning_rate': 0.007807871507022511}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:00:49,928]\u001b[0m Trial 51 finished with value: 0.21014285714285713 and parameters: {'n_estimators': 100, 'depth': 71, 'leaves': 35334, 'learning_rate': 0.0001114688627687035}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:01:15,831]\u001b[0m Trial 52 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 75, 'depth': 63, 'leaves': 81278, 'learning_rate': 0.001431225401182098}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:01:45,519]\u001b[0m Trial 53 finished with value: 0.9792857142857143 and parameters: {'n_estimators': 75, 'depth': 61, 'leaves': 84218, 'learning_rate': 0.00043185255070150267}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:02:00,962]\u001b[0m Trial 54 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 44, 'depth': 65, 'leaves': 84271, 'learning_rate': 0.0013582413636391022}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:02:14,343]\u001b[0m Trial 55 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 95, 'depth': 80, 'leaves': 41157, 'learning_rate': 0.0008062346126521362}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:02:29,331]\u001b[0m Trial 56 finished with value: 0.5829285714285715 and parameters: {'n_estimators': 45, 'depth': 72, 'leaves': 77742, 'learning_rate': 0.00029770762128886587}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:03:13,365]\u001b[0m Trial 57 finished with value: 0.1105 and parameters: {'n_estimators': 95, 'depth': 56, 'leaves': 99574, 'learning_rate': 6.834769392590952e-05}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:03:47,382]\u001b[0m Trial 58 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 83, 'depth': 91, 'leaves': 88262, 'learning_rate': 0.005190209131740729}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:03:56,011]\u001b[0m Trial 59 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 100, 'depth': 74, 'leaves': 24475, 'learning_rate': 0.0028449357925318737}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:04:06,902]\u001b[0m Trial 60 finished with value: 0.9808571428571429 and parameters: {'n_estimators': 84, 'depth': 97, 'leaves': 38802, 'learning_rate': 0.025116383694953476}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:04:48,387]\u001b[0m Trial 61 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 89, 'depth': 68, 'leaves': 98686, 'learning_rate': 0.0037741430217382017}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:05:25,032]\u001b[0m Trial 62 finished with value: 0.9809285714285715 and parameters: {'n_estimators': 88, 'depth': 69, 'leaves': 94787, 'learning_rate': 0.008391989557986188}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:05:49,779]\u001b[0m Trial 63 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 56, 'depth': 45, 'leaves': 94867, 'learning_rate': 0.0010914995965298274}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:06:03,732]\u001b[0m Trial 64 finished with value: 0.9798571428571429 and parameters: {'n_estimators': 33, 'depth': 59, 'leaves': 95434, 'learning_rate': 0.0010959842614928572}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:06:30,918]\u001b[0m Trial 65 finished with value: 0.9809285714285715 and parameters: {'n_estimators': 69, 'depth': 65, 'leaves': 87234, 'learning_rate': 0.011696929513938789}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:06:51,046]\u001b[0m Trial 66 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 78, 'depth': 36, 'leaves': 63306, 'learning_rate': 0.0018969794884466037}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:06:52,508]\u001b[0m Trial 67 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 53, 'depth': 10, 'leaves': 33437, 'learning_rate': 0.006710110284384297}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 12:06:57,908]\u001b[0m Trial 68 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 62, 'depth': 20, 'leaves': 25517, 'learning_rate': 0.002323496068107836}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:06:58,132]\u001b[0m Trial 69 finished with value: 0.981 and parameters: {'n_estimators': 53, 'depth': 1, 'leaves': 34897, 'learning_rate': 0.018526975646749128}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:14,394]\u001b[0m Trial 70 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 87, 'depth': 32, 'leaves': 53148, 'learning_rate': 0.0032653709372688533}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:15,481]\u001b[0m Trial 71 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 65, 'depth': 8, 'leaves': 32132, 'learning_rate': 0.005856246117456259}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:26,162]\u001b[0m Trial 72 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 66, 'depth': 16, 'leaves': 45112, 'learning_rate': 0.002365641033122417}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:27,116]\u001b[0m Trial 73 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 60, 'depth': 7, 'leaves': 30647, 'learning_rate': 0.006263182367469923}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:38,975]\u001b[0m Trial 74 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 64, 'depth': 16, 'leaves': 47010, 'learning_rate': 0.0023575868992272426}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:39,412]\u001b[0m Trial 75 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 59, 'depth': 4, 'leaves': 17281, 'learning_rate': 0.00846867768367582}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:47,449]\u001b[0m Trial 76 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 56, 'depth': 16, 'leaves': 45334, 'learning_rate': 0.0019989109127519127}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:07:48,112]\u001b[0m Trial 77 finished with value: 0.981 and parameters: {'n_estimators': 92, 'depth': 4, 'leaves': 15870, 'learning_rate': 0.02205666414949405}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:08:11,096]\u001b[0m Trial 78 finished with value: 0.9805 and parameters: {'n_estimators': 72, 'depth': 51, 'leaves': 78043, 'learning_rate': 0.0005852237020918196}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:08:13,689]\u001b[0m Trial 79 finished with value: 0.981 and parameters: {'n_estimators': 56, 'depth': 12, 'leaves': 25382, 'learning_rate': 0.01129848654121795}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:08:18,472]\u001b[0m Trial 80 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 80, 'depth': 83, 'leaves': 10424, 'learning_rate': 0.0037507568389909015}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:08:36,572]\u001b[0m Trial 81 finished with value: 0.9807142857142858 and parameters: {'n_estimators': 91, 'depth': 40, 'leaves': 49906, 'learning_rate': 0.0004737159778757506}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:08:41,305]\u001b[0m Trial 82 finished with value: 0.978 and parameters: {'n_estimators': 51, 'depth': 25, 'leaves': 27999, 'learning_rate': 0.0005893539838850257}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:09:04,521]\u001b[0m Trial 83 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 93, 'depth': 37, 'leaves': 62086, 'learning_rate': 0.0017489780097103772}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:09:21,810]\u001b[0m Trial 84 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 90, 'depth': 43, 'leaves': 53574, 'learning_rate': 0.0009299300408315675}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:09:42,422]\u001b[0m Trial 85 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 92, 'depth': 39, 'leaves': 60384, 'learning_rate': 0.001485027737299365}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:10:01,266]\u001b[0m Trial 86 finished with value: 0.9741428571428571 and parameters: {'n_estimators': 97, 'depth': 43, 'leaves': 53160, 'learning_rate': 0.0002677473670087266}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:10:11,724]\u001b[0m Trial 87 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 68, 'depth': 20, 'leaves': 44599, 'learning_rate': 0.0013504572646800346}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:10:22,797]\u001b[0m Trial 88 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 82, 'depth': 52, 'leaves': 36887, 'learning_rate': 0.0008621545463576891}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:10:29,720]\u001b[0m Trial 89 finished with value: 0.9808571428571429 and parameters: {'n_estimators': 58, 'depth': 53, 'leaves': 36495, 'learning_rate': 0.034664241306597114}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:10:42,351]\u001b[0m Trial 90 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 95, 'depth': 78, 'leaves': 40982, 'learning_rate': 0.004198400515665295}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:11:01,663]\u001b[0m Trial 91 finished with value: 0.9796428571428571 and parameters: {'n_estimators': 44, 'depth': 91, 'leaves': 87011, 'learning_rate': 0.0007620781299361351}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:11:06,103]\u001b[0m Trial 92 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 96, 'depth': 13, 'leaves': 51424, 'learning_rate': 0.004391515644136951}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:11:19,512]\u001b[0m Trial 93 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 35, 'depth': 74, 'leaves': 91878, 'learning_rate': 0.0014093391729884644}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:11:41,266]\u001b[0m Trial 94 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 75, 'depth': 80, 'leaves': 72116, 'learning_rate': 0.004761239198833058}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:11:54,307]\u001b[0m Trial 95 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 30, 'depth': 73, 'leaves': 81533, 'learning_rate': 0.003341188192540322}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:12:12,935]\u001b[0m Trial 96 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 46, 'depth': 88, 'leaves': 95652, 'learning_rate': 0.001122860311459777}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:12:22,706]\u001b[0m Trial 97 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 24, 'depth': 68, 'leaves': 81371, 'learning_rate': 0.0028397953769957116}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:12:40,663]\u001b[0m Trial 98 finished with value: 0.9810714285714286 and parameters: {'n_estimators': 41, 'depth': 64, 'leaves': 87354, 'learning_rate': 0.0019809742284112816}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n",
      "\u001b[32m[I 2021-03-02 12:12:45,107]\u001b[0m Trial 99 finished with value: 0.1105 and parameters: {'n_estimators': 14, 'depth': 62, 'leaves': 74655, 'learning_rate': 0.00033498260473649406}. Best is trial 1 with value: 0.9810714285714286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial score : 0.9810714285714286\n",
      "Best Params: {'n_estimators': 11, 'depth': 48, 'leaves': 54784, 'learning_rate': 0.01781553514487793}\n"
     ]
    }
   ],
   "source": [
    "# Stacking 된 데이터로 lgbm 모델 튜닝\n",
    "def lgbm_objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "    depth = trial.suggest_int('depth', 1, 100)\n",
    "    leaves = trial.suggest_int('leaves', 1, 100000)\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-5, 1)\n",
    "    \n",
    "    classifier_obj = LGBMClassifier(n_estimators=n_estimators, max_depth=depth, num_leaves=leaves, learning_rate = lr, random_state=42)\n",
    "    \n",
    "    classifier_obj.fit(s_train, y_train.reshape(-1))\n",
    "    accuracy = accuracy_score(y_val, classifier_obj.predict(s_test))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "lgbm_study = optuna.create_study(direction='maximize')\n",
    "lgbm_study.optimize(lgbm_objective, n_trials=100)\n",
    "print(f\"Best trial score : {lgbm_study.best_trial.value}\\nBest Params: {lgbm_study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "predModel = LGBMClassifier(random_state=42, n_estimators= 82, max_depth= 53, learning_rate= 0.0011809564065541087)\n",
    "predModel.fit(s_train, y_train)\n",
    "prediction = predModel.predict(s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9810714285714286\n"
     ]
    }
   ],
   "source": [
    "# 튜닝 후 정확도 (validation)\n",
    "print(f\"accuracy_score: {accuracy_score(y_val, prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [10]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [4]\n",
      "\n",
      "estimator  0: [lr: LogisticRegression]\n",
      "    fold  0:  [0.92492857]\n",
      "    fold  1:  [0.91507143]\n",
      "    fold  2:  [0.92050000]\n",
      "    fold  3:  [0.91685714]\n",
      "    ----\n",
      "    MEAN:     [0.91933929] + [0.00377369]\n",
      "\n",
      "estimator  1: [svc: SVC]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.98400000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.98207143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.98292857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/svm/_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.98350000]\n",
      "    ----\n",
      "    MEAN:     [0.98312500] + [0.00071674]\n",
      "\n",
      "estimator  2: [ada: AdaBoostClassifier]\n",
      "    fold  0:  [0.78435714]\n",
      "    fold  1:  [0.77350000]\n",
      "    fold  2:  [0.78707143]\n",
      "    fold  3:  [0.76921429]\n",
      "    ----\n",
      "    MEAN:     [0.77853571] + [0.00739924]\n",
      "\n",
      "estimator  3: [rf: RandomForestClassifier]\n",
      "    fold  0:  [0.96907143]\n",
      "    fold  1:  [0.96435714]\n",
      "    fold  2:  [0.96400000]\n",
      "    fold  3:  [0.96521429]\n",
      "    ----\n",
      "    MEAN:     [0.96566071] + [0.00201802]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lr: LogisticRegression]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [svc: SVC]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [ada: AdaBoostClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [lr: LogisticRegression]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [svc: SVC]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [ada: AdaBoostClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  3: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.0011809564065541087, max_depth=53,\n",
       "               n_estimators=82, random_state=42)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 튜닝 된 모델을 사용하여 다시 스태킹 후 결과값 확인\n",
    "# 차후에 예측을 조금 더 편하게 하기 위해 StackingTransformer 사용.\n",
    "\n",
    "from vecstack import StackingTransformer\n",
    "\n",
    "lr = LogisticRegression(max_iter=5000, random_state=42)\n",
    "svc = SVC(random_state = 42, C= 14.971964747211656, max_iter=1000)\n",
    "ada = AdaBoostClassifier(random_state=42, n_estimators = 96, learning_rate= 0.6610069832017895)\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators= 95, max_depth= 28)\n",
    "lgbm = LGBMClassifier(random_state=42, n_estimators= 82, max_depth= 53, learning_rate= 0.0011809564065541087)\n",
    "\n",
    "# Initialize 1st level estimators\n",
    "estimators = [('lr', lr), ('svc', svc), ('ada', ada), ('rf', rf)]\n",
    "              \n",
    "# Initialize StackingTransformer\n",
    "stack = StackingTransformer(estimators, regression=False, verbose=2, random_state=None)\n",
    "\n",
    "# Fit\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# Get your stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_test = stack.transform(X_test) # 여기서 데이터를 미리 분할해 놓고 차후에 사용한다.\n",
    "\n",
    "predModel = LGBMClassifier(random_state=42, n_estimators= 82, max_depth= 53, learning_rate= 0.0011809564065541087)\n",
    "predModel.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting 방법 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train이 변경되었으므로 다시 분할해주어야 한다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: probability\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "accuracy_score: 0.9770714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "lr = LogisticRegression(max_iter=5000, random_state=42)\n",
    "svc = SVC(random_state = 42, C= 14.971964747211656, max_iter=10000, probability=True)\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators= 95, max_depth= 28)\n",
    "lgbm = LGBMClassifier(random_state=42, n_estimators= 82, max_depth= 53, learning_rate= 0.0011809564065541087, probability=True)\n",
    "\n",
    "votingModel = VotingClassifier(\n",
    "    estimators=[('lr', lr), ('svc', svc), ('rf', rf), ('lgbm', lgbm)],\n",
    "    voting='soft' # 모델이 잘 튜닝된 모델이므로 soft 방법을 사용\n",
    ")\n",
    "\n",
    "votingModel.fit(pca_x, y_train.reshape(-1))\n",
    "\n",
    "prediction = votingModel.predict(pca_test_X)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 모델 성능\n",
    "\n",
    "Stacking 된 모델과 튜닝 과정에서 가장 성능이 좋았던 모델인 SVC 모델, Voting 모델의 결과를 적어 두었다.\n",
    "\n",
    "SVC 모델의 경우, 정확도가 0.98786 정도로 상당히 높게 나온 것을 확인할 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.982\n"
     ]
    }
   ],
   "source": [
    "# 튜닝 후 stacking 의 test 데이터 정확도\n",
    "prediction = predModel.predict(S_test)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9770714285714286\n"
     ]
    }
   ],
   "source": [
    "# Voting 방법의 test 데이터 정확도\n",
    "prediction = votingModel.predict(pca_test_X)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.9878571428571429\n"
     ]
    }
   ],
   "source": [
    "# 튜닝 후 SVM의 test 데이터 정확도\n",
    "predModel2 = SVC(C=14.971964747211656, random_state=42, max_iter=10000)\n",
    "predModel2.fit(pca_x, y_train.reshape(-1))\n",
    "\n",
    "prediction = predModel2.predict(pca_test_X)\n",
    "print(f\"accuracy_score: {accuracy_score(y_test, prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 LDA 보다 PCA의 데이터 정확도가 더 높았을까?\n",
    "\n",
    "[이 글](https://kjwan4435.tistory.com/85) 에 따르면 데이터의 차이가 평균보다 분산에 더 있을 때 PCA가 효과적이라고 나와 있다.\n",
    "\n",
    "MNIST 데이터는 모든 픽셀 값이 0~1 사이 이므로 각 숫자 클래스별로 평균 별 차이가 크지 않을 것으로 생각된다.\n",
    "\n",
    "반면, 숫자의 모양에 따라 픽셀이 칠해진 위치가 다를 것이므로 분산은 클래스 별로 차이가 있을 것이라고 (직관에 의해) 추측된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
