{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/AugustLONG/ML01/master/01decisiontree/AllElectronics.csv')\n",
    "df.drop(\"RID\",axis=1, inplace = True) #RID는 그냥 Index라서 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>student</th>\n",
       "      <th>credit_rating</th>\n",
       "      <th>class_buys_computer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youth</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>youth</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>middle_aged</td>\n",
       "      <td>high</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>senior</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>senior</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>senior</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>middle_aged</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>youth</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>fair</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>youth</td>\n",
       "      <td>low</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>senior</td>\n",
       "      <td>medium</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>youth</td>\n",
       "      <td>medium</td>\n",
       "      <td>yes</td>\n",
       "      <td>excellent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>middle_aged</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>middle_aged</td>\n",
       "      <td>high</td>\n",
       "      <td>yes</td>\n",
       "      <td>fair</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>senior</td>\n",
       "      <td>medium</td>\n",
       "      <td>no</td>\n",
       "      <td>excellent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  income student credit_rating class_buys_computer\n",
       "0         youth    high      no          fair                  no\n",
       "1         youth    high      no     excellent                  no\n",
       "2   middle_aged    high      no          fair                 yes\n",
       "3        senior  medium      no          fair                 yes\n",
       "4        senior     low     yes          fair                 yes\n",
       "5        senior     low     yes     excellent                  no\n",
       "6   middle_aged     low     yes     excellent                 yes\n",
       "7         youth  medium      no          fair                  no\n",
       "8         youth     low     yes          fair                 yes\n",
       "9        senior  medium     yes          fair                 yes\n",
       "10        youth  medium     yes     excellent                 yes\n",
       "11  middle_aged  medium      no     excellent                 yes\n",
       "12  middle_aged    high     yes          fair                 yes\n",
       "13       senior  medium      no     excellent                  no"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy를 구하는 식은 $-\\sum_{k = 1}^{m}p_klog_2{p_k}$이다.\n",
    "\n",
    "우선 Series.value_counts함수를 사용하여 주어진 feature의 class별 확률을 구한다.\n",
    "\n",
    "이후 초기값 entropy = 0이후 계산식에 따라 for문을 돌며 $plog_2{p}$를 빼주어 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(df, feature):\n",
    "    entropy = 0 # entropy값 초기화\n",
    "    ps = df[feature].value_counts() / len(df)\n",
    "    # pandas.Series.value_counts함수를 이용하여 feature의 class별 확률을 계산\n",
    "    for p in ps:\n",
    "        entropy -= p * np.log2(p)\n",
    "        # entropy에 p * log2(p)를 빼주어 최종 entropy계산\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402859586706311"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getEntropy(df, \"class_buys_computer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "의사결정나무는 분기를 위한 feature를 결정하기 위해서 entropy을 기준으로 활용한다.\n",
    "\n",
    "그 기준 Information Gain이란 상위노드의 entropy에서 하위노드의 entropy를 뺀 값이다.\n",
    "\n",
    "Information_Gain(S, F) $= e(S) - \\sum_{f\\in{F}} \\frac{S_f}{S}e(S_f)$이다.\n",
    "\n",
    "식을 풀어보면 분기 전 노드의 entropy에서 분기할 feature의 class별 entropy를 가중평균한 값을 빼준다. \n",
    "\n",
    "즉, Information Gain은 분기 전 entropy와 분기 후 entropy의 차이로 그 차이가 클수록 분류가 잘 되고있음을 뜻한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGainA(df, feature) :\n",
    "    \n",
    "    def entropy_by_target(df, feature, feature_under):\n",
    "        entropy = 0 #entropy값 초기화\n",
    "        n = len(df)\n",
    "        # 추후 feature_under의 class별 가중평균을 위해 전체 샘플 수 저장\n",
    "        unique = df[feature_under].unique()\n",
    "        # feature_under의 class를 unique변수에 저장\n",
    "        \n",
    "        for i in unique: # feature_under의 class별 for\n",
    "            tmp_df = df[df[feature_under].isin([i])] \n",
    "            # isin함수를 사용하여 feature_under의 class가 i인 것만 저장\n",
    "            entropy += len(tmp_df) / n * getEntropy(tmp_df, feature)\n",
    "            # 위에서 정의한 getEntropy함수를 통해 target feature의 entropy를 가중평균함\n",
    "        return entropy\n",
    "        \n",
    "    info_D = getEntropy(df, feature) # 목표변수 Feature에 대한 Info(Entropy)를 구함\n",
    "    columns = list(df.loc[:, df.columns != feature])\n",
    "    # 목표변수를 제외한 나머지 설명변수들을 리스트 형태로 저장\n",
    "    result = dict() # 결과 dictionary\n",
    "    \n",
    "    for feature_under in columns:\n",
    "        result[feature_under] = info_D - entropy_by_target(df, feature, feature_under)\n",
    "        # entropy_by_target함수를 이용하여 entropy를 계산한 후 info_D에서 빼서 information gain을 계산\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0.24674981977443933,\n",
       " 'income': 0.02922256565895487,\n",
       " 'student': 0.15183550136234159,\n",
       " 'credit_rating': 0.04812703040826949}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getGainA(df, \"class_buys_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
