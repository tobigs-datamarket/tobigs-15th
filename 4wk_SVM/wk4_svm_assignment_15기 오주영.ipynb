{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HyMvTfrPTEU"
   },
   "source": [
    "### TOBIG'S 14기 정규세션 4주차 SVM \n",
    "### ASSIGNMENT1. Multiclass SVM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMqxwjbRNX6u",
    "outputId": "f7b6519f-9521-446b-a107-044a7113bc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#IRIS 데이터 로드\n",
    "iris =  sns.load_dataset('iris') \n",
    "X= iris.iloc[:,:4] #학습할데이터\n",
    "y = iris.iloc[:,-1] #타겟\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(train, test):\n",
    "    scaler = StandardScaler()\n",
    "    train = scaler.fit_transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return train, test\n",
    "\n",
    "X_train, X_test = standardization(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드의 재사용성을 위해 label의 class수와 무관한 분류기를 OVR형식으로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_OVR:\n",
    "    def __init__(self, num_classes, kernel, C, gamma):\n",
    "        self.num_classes = num_classes\n",
    "        self.clfs = [SVC(kernel = kernel, C = C, gamma = gamma) for _ in range(num_classes)]\n",
    "        self.classes = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        y_train = pd.get_dummies(y_train)\n",
    "        for i in range(self.num_classes):\n",
    "            self.clfs[i].fit(X_train,y_train.iloc[:,i]) \n",
    "            # 각 클래스별로 인지 아닌지를 판단하는 분류기를 학습시킵니다.\n",
    "        self.classes = y_train.columns\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        pred_df = pd.DataFrame([svm.predict(X_test) for svm in self.clfs]).T # 각 클래스 별 예측값\n",
    "        decisions = np.array([svm.decision_function(X_test) for svm in self.clfs]).T # 각 클래스 별 거리\n",
    "        \n",
    "        final_pred = []\n",
    "        for i in range(len(pred_df)):\n",
    "            # 예측 중 하나의 클래스만 맞다고 판단한 경우\n",
    "            # 맞다고 판단도니 클래스를 final_pred 리스트에 넣어준다\n",
    "            if sum(pred_df.iloc[i]) == 1:\n",
    "                label = pred_df.iloc[i][pred_df.iloc[i] == 1].index[0]\n",
    "                final_pred.append(self.classes[label])\n",
    "            \n",
    "            # 두개 이상 혹은 전부 아니라고 판단한 경우\n",
    "            # 결정경계를 이용한다.\n",
    "            \n",
    "            # case1 : 예측 중 두개 이상의 클래스가 맞다고 판단한 경우\n",
    "            #         맞다고 판단된 클래스 중 결정경계로부터 더 먼 클래스를 리스트에 넣어준다.\n",
    "            #         맞는 클래스의 경우 결정경계로부터 거리가 양수로 나타나므로 argmax를 이용\n",
    "            \n",
    "            # case2 : 예측 중 전부 아니라고 판단한 경우\n",
    "            #         결정경계로부터 가장 가까운 클래스를 리스트에 넣어준다.\n",
    "            #         전부 아니라고 판단햇으므로 결정경계로부터 거리가 모두 음수이므로 argmax이용\n",
    "            \n",
    "            # 두가지 케이스를 살펴본 결과\n",
    "            # 모두 결정경계로부터 거리의 argmax를 final label로 채택할 수 있음\n",
    "            \n",
    "            else:\n",
    "                label = np.argmax(decisions[i])\n",
    "                final_pred.append(self.classes[label])\n",
    "        \n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_OVR(num_classes = 3, kernel = 'rbf', C = 5, gamma = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor          versicolor\n",
      "versicolor          versicolor\n",
      "virginica          versicolor\n",
      "setosa           virginica\n",
      "versicolor           virginica\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "versicolor          versicolor\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "versicolor          versicolor\n",
      "versicolor          versicolor\n",
      "setosa              setosa\n",
      "versicolor          versicolor\n",
      "versicolor           virginica\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "versicolor          versicolor\n",
      "versicolor          versicolor\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "virginica           virginica\n",
      "versicolor          versicolor\n"
     ]
    }
   ],
   "source": [
    "for gt, pr in zip(y_test, pred):\n",
    "    print('%s%20s'%(gt, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드의 재사용성을 위해 label의 class수와 무관한 분류기를 OVO형식으로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_OVO:\n",
    "    def __init__(self, num_classes, kernel, C, gamma):\n",
    "        self.num_classes = num_classes\n",
    "        self.clfs = [{'class' : None,'clf' : SVC(kernel = kernel, C = C, gamma = gamma)} for _ in range(int(num_classes * (num_classes-1) / 2))]\n",
    "        # num_classes의 조합의 수만큼 분류기를 만듭니다.\n",
    "        self.classes = None\n",
    "        self.combi = []\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes = y_train.unique()\n",
    "        i = 0\n",
    "        # classes의 조합 별로 idx를 나눠 각 조합별로 svm을 훈련시킵니다.\n",
    "        for c in combinations(self.classes, 2):\n",
    "            idx = (y_train == c[0]) | (y_train == c[1])\n",
    "            self.clfs[i]['clf'].fit(X_train[idx], y_train[idx])\n",
    "            self.clfs[i]['class'] = c\n",
    "            self.combi.append(c)\n",
    "            i += 1\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        preds_df = pd.DataFrame([svm['clf'].predict(X_test) for svm in self.clfs]).T # 각 조합 별 예측\n",
    "        decisions = pd.DataFrame([svm['clf'].decision_function(X_test) for svm in self.clfs]).T # 각 클래스 별 거리\n",
    "        decisions.columns = self.combi\n",
    "        \n",
    "        final_pred = []\n",
    "        for i in range(len(preds_df)):\n",
    "            \n",
    "            # 예측들 중 가장 많은 한 클래스가 있을 경우\n",
    "            # 해당 클래스를 리스트에 넣어준다\n",
    "            if preds_df.iloc[i].value_counts().iloc[0] > preds_df.iloc[i].value_counts().iloc[1]:\n",
    "                label = (preds_df.iloc[i].value_counts() / len(preds_df.iloc[i])).index[0]\n",
    "                final_pred.append(label)\n",
    "            \n",
    "            # 겹치는 클래스가 존재하거나 모든 클래스가 다를 경우\n",
    "            # 클래스에 해당하는 결정경계로부터 거리의 합이 큰 클래스를 선택한다\n",
    "            else:\n",
    "                decision_for_row = {key : 0 for key in classes}\n",
    "                for c, d in zip(decisions.iloc[i].index, decisions.iloc[i]):\n",
    "                    if d > 0:\n",
    "                        decision_for_row[c[0]] += d\n",
    "                    else:\n",
    "                        decision_for_row[c[1]] -= d\n",
    "                label = sorted(decision_for_row.items(), key = lambda x : x[1], reverse = True)[0][0]\n",
    "                final_pred.append(label)\n",
    "        return final_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_OVO(num_classes = 3, kernel = 'rbf', C = 5, gamma = 5)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "versicolor          versicolor\n",
      "versicolor          versicolor\n",
      "virginica          versicolor\n",
      "setosa           virginica\n",
      "versicolor           virginica\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "versicolor          versicolor\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "versicolor          versicolor\n",
      "versicolor          versicolor\n",
      "setosa              setosa\n",
      "versicolor          versicolor\n",
      "versicolor           virginica\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "versicolor          versicolor\n",
      "versicolor          versicolor\n",
      "virginica           virginica\n",
      "setosa              setosa\n",
      "setosa              setosa\n",
      "virginica           virginica\n",
      "virginica           virginica\n",
      "versicolor          versicolor\n"
     ]
    }
   ],
   "source": [
    "for gt, pr in zip(y_test, pred):\n",
    "    print('%s%20s'%(gt, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn 라이브러리를 활용한 multi class svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlVlC9l9NX77",
    "outputId": "46f7603d-a673-498e-8a9e-a0cb79cc9468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 라이브러리가 제공하는 multi class SVM과 여러분이 구현한 multiclass SVM 결과를 비교해주세요\n",
    "svm = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 구현한 SVM_OVR, SVM_OVO를 다른 데이터셋에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = load_digits()\n",
    "X = pd.DataFrame(mnist.data)\n",
    "y = pd.Series(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#간단하게 16으로 나누어 데이터를 정규화합니다.\n",
    "X /= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=317)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_OVR(num_classes = 10, kernel = 'rbf', C = 1, gamma = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM_OVO(num_classes = 10, kernel = 'rbf', C = 1, gamma = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9805555555555555"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다른 데이터 셋에도 잘 작동하는것을 확인함\n",
    "- OVO의 경우 조합의 수만큼 분류기를 만들기 때문에 OVR에 비해 시간이 더 많이 걸림\n",
    "- 보통 OVO의 성능이 더 좋다고 알려져있지만 OVO의 성능이 OVR보다 떨어짐. 단순히 거리의 합을 기준으로 하기 때문일것이라 판단됨.\n",
    "- ovo 개선점 : svm의 predict_proba기능을 사용하여 확률의 합을 이용해 볼 수 있을것같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment_1.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
