{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HyMvTfrPTEU"
   },
   "source": [
    "#### TOBIG'S 14기 정규세션 4주차 SVM \n",
    "### ASSIGNMENT1. Multiclass SVM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMqxwjbRNX6u",
    "outputId": "f7b6519f-9521-446b-a107-044a7113bc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score # 정확도 파악을 위한 패키지 임포트\n",
    "#IRIS 데이터 로드\n",
    "iris =  sns.load_dataset('iris') \n",
    "X= iris.iloc[:,:4] #학습할데이터\n",
    "y = iris.iloc[:,-1] #타겟\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tm8gpfVSNX67"
   },
   "outputs": [],
   "source": [
    "scal = StandardScaler() #scaling\n",
    "X = scal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "laRcz10bNX7C",
    "outputId": "66f6f6c2-38fb-4da2-bb76-560838244c24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         setosa\n",
      "1         setosa\n",
      "2         setosa\n",
      "3         setosa\n",
      "4         setosa\n",
      "         ...    \n",
      "145    virginica\n",
      "146    virginica\n",
      "147    virginica\n",
      "148    virginica\n",
      "149    virginica\n",
      "Name: species, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7VgXR-SNX7K"
   },
   "outputs": [],
   "source": [
    "# One VS Rest 구현을 위해 1) class가 0 or not 2)class가 1 or not을 구분하기 위한 머신 등을 미리 만들어주자\n",
    "svm_1 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_2 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_3 = SVC(kernel ='rbf', C = 5, gamma = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pyMSHOFHNX7R"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #test/train 데이터로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KnlaqAJNX7X"
   },
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train) #one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dummies` 를 통해 각 클래스의 ont-hot 인코딩을 실시한다.\n",
    "\n",
    "따라서 y_train은 (n,3) shape 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "110       0           0          1\n",
       "69        0           1          0\n",
       "148       0           0          1\n",
       "39        1           0          0\n",
       "53        0           1          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head() #데이터 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9S5ML8x1NX7d",
    "outputId": "598fe774-41b4-4552-b7f6-b2a650e57897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
      "[-1.12470845 -0.86326953 -0.65281099 -0.50248821 -0.76284323 -0.87465573\n",
      "  1.07709345 -0.99281647  0.47441336 -0.99842743 -0.83989348  0.15633457\n",
      "  0.32871788 -0.97965464 -0.72385083 -0.92638376  1.28322481 -0.56240455\n",
      " -0.72719892 -0.99509775  0.43166724 -0.96451557 -0.82991366 -1.03020581\n",
      " -0.75166835  1.13461335  0.39943974 -1.04194106 -0.93376548 -1.06133798]\n"
     ]
    }
   ],
   "source": [
    "svm_1.fit(X_train,y_train.iloc[:,0]) # 데이터 클레스가 0 or not 구분해주는 머신\n",
    "svm_2.fit(X_train,y_train.iloc[:,1]) # 데이터 클레스가 1 or not 구분해주는 머신\n",
    "svm_3.fit(X_train,y_train.iloc[:,2]) # 데이터 클레스가 2 or not 구분해주는 머신\n",
    "print(svm_1.predict(X_test)) #데이터 클래스가 0 or not을 구분해주는 애를 통해서 테스트 데이터의 클래스가 0인지, 0이 아닌인지 예측해보자\n",
    "\n",
    "print(svm_1.decision_function(X_test)) #decision_function hyperplane과의 거리를 구하는 방법(필요하다면 활용해주세요!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y_train.iloc[: n]` 을 시행하면, 해당 클래스인지 아닌지 여부를 알 수 있다.\n",
    "즉 한 행씩 따로 쪼개면 이진 분류가 가능하다는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCR46aMrNX7p",
    "outputId": "ec7adcec-d0e8-4dd8-f2df-4cd063a19867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score is same at index[3].\n",
      "Decision_function of svm_1: -0.5024882107322184 predict : 0\n",
      "Decision_function of svm_2: -0.36987092513822756 predict : 0\n",
      "Decision_function of svm_3: -0.13070947139128608 predict : 0\n",
      "The Score is same at index[17].\n",
      "Decision_function of svm_1: -0.562404550285589 predict : 0\n",
      "Decision_function of svm_2: -0.18705039695337913 predict : 0\n",
      "Decision_function of svm_3: -0.2533393758266559 predict : 0\n",
      "The Score is same at index[18].\n",
      "Decision_function of svm_1: -0.7271989224328648 predict : 0\n",
      "Decision_function of svm_2: -0.24458235766281572 predict : 0\n",
      "Decision_function of svm_3: -0.025197903756274675 predict : 0\n"
     ]
    }
   ],
   "source": [
    "# 부호가 모든 같은 경우가 있는가? > 모두 동점인 경우가 생길 것\n",
    "for i in range(len(X_test)):\n",
    "    # ~. decision_function을 이용하면 해당 데이터가 하이퍼플레인으로부터 얼마나 떨어져있는지 '거리'가 나온다!\n",
    "    # 다음은 그 값의 부호를 이용해 모두가 동점인 경우가 있는지 출력하는 함수 \n",
    "    if (np.sign(svm_1.decision_function(X_test)[i]) == np.sign(svm_2.decision_function(X_test)[i])) and (np.sign(svm_2.decision_function(X_test)[i]) == np.sign(svm_3.decision_function(X_test)[i])):\n",
    "        print(f\"The Score is same at index[{i}].\")\n",
    "        print(f\"Decision_function of svm_1: {svm_1.decision_function(X_test)[i]} predict : {svm_1.predict(X_test)[i]}\")\n",
    "        print(f\"Decision_function of svm_2: {svm_2.decision_function(X_test)[i]} predict : {svm_2.predict(X_test)[i]}\")\n",
    "        print(f\"Decision_function of svm_3: {svm_3.decision_function(X_test)[i]} predict : {svm_2.predict(X_test)[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세 데이터가 모두 같은 경우를 반복문을 통해서 확인한 뒤 같은 데이터의 인덱스를 출력했다.\n",
    "\n",
    "추가로 확인을 위해 덧붙여서 Decision_function 과 Predict 값을 확인해 두었다.\n",
    "\n",
    "3, 17, 18의 3개가 동점 데이터를 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1\n",
    "\n",
    "처음에는 Voting 방식으로 평가를 진행했으나, 모두 0표가 되는 등 동점 상황이 발생하는 문제가 생겼다.\n",
    "\n",
    "이를 해결하기 위해 1표씩 주는 것이 아니라, 서로 얼마나 떨어져 있는지를 나타내는 Decision_function을 사용하기로 결정했다.\n",
    "\n",
    "각 모델이 서로 얼마나 떨어져 있는지를 나타내기 때문에 다음과 같은 결과 패턴을 보일 것으로 생각이 되었다.\n",
    "- 정상적으로 예측 결과가 나왔을 때 (한 곳에서만 값이 1일때) : 한 곳에서만 Decision_function값이 양수가 나왔을 것이다.\n",
    "- 2개 이상의 클래스로 예측되었을 때 (두 개 이상의 1이 나왔을 때) : 복수의 클래스 중 더 특성을 잘 나타내는 클래스의 Decision_function값(양수)이 클 것이다.\n",
    "- 어떠한 클래스로도 예측되지 않았을 때 (모두 0의 값일때) : 그나마 가장 가까운 클래스의 Decision_function값이 음수이며 절대값이 가장 작을 것이다. (셋 중 가장 크다)\n",
    "\n",
    "따라서 각 세 모델의 Dicision_function을 구한 뒤 이의 `argmax()`를 취해 주면 될 것으로 생각했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : \n",
      " ['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Case 1 : One vs Rest SVM을 이부분에 구현해주세요 위 결과들을 이용해서 multi class SVM을 직접 구현해주세요! 하드코딩이 하시기 편할겁니다.\n",
    "\n",
    "# 동점 처리를 위해서 단순 Count가 아니라 Decision_function 의 값을 가중치로 해서 더하는 방식을 사용하겠습니다.\n",
    "# Decision_function 데이터가 얼마나 떨어져 있는지 거리이기 때문에, 절대값이 클 수록 점수에 미치는 영향력이 클 것으로 생각된다.\n",
    "# 각 모델에게서 예측된 값을 배열에 담아서 비교하면 값이 양수인 곳이 해당 클래스일 가능성이 매우 높다고 판단했다.\n",
    "# 따라서 모든 데이터의 argmax 값을 비교해서 가장 큰 argmax 값을 가지는 것을 최종 데이터로 삼고자 한다.\n",
    "\n",
    "def one_rest_svm_predict(models, data, labels): # 함수로 분리해서 계산\n",
    "    distance = None # 빈 배열 초기화\n",
    "    \n",
    "    for model in models: # 각 모델에 대해 예측 실시\n",
    "        if distance is None:\n",
    "            distance = model.decision_function(data) # 모델이 비어있으면 배열 생성\n",
    "        else:\n",
    "            distance = np.vstack((distance, model.decision_function(data))) # 모델이 비어있지 않으면 배열 stack\n",
    "            \n",
    "    # 반복문 수행 후 distacne 의 row에는 모델의 수 , columns 에는 len(data) 가 저장된다.\n",
    "    # 계산의 편의를 위해 Transpose\n",
    "    distance = distance.T\n",
    "    \n",
    "    result = [] # 결과값에 대한 distance를 저장하는 배열 생성\n",
    "    \n",
    "    for pred in distance:\n",
    "        result.append(labels[pred.argmax()]) # 각 예측들에 대해서 가장 큰 값을 가지는 결과값(argmax) 에 해당하는 꽃을 저장\n",
    "\n",
    "    \n",
    "    print(f\"prediction : \\n {result}\")\n",
    "    return result\n",
    "\n",
    "models = [svm_1, svm_2, svm_3]\n",
    "labels = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "prediction = one_rest_svm_predict(models, X_test, labels)\n",
    "\n",
    "accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 예측되는 것을 확인할 수 있었다.\n",
    "\n",
    "# Case 2\n",
    "\n",
    "One vs One 을 사용하면 총 클래스가 3개이므로 3개의 예측기가 필요하다. ((0,1), (0,2), (1,2))\n",
    "\n",
    "이 예측기를 학습시키기 위해서는 2개의 클래스로만 구성된 학습용 데이터가 필요했다.\n",
    "\n",
    "따라서 특정 클래스를 제외한 3개의 데이터를 다시 만들어 각각 학습시켰다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48) # 다시 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [\"setosa\", \"versicolor\", \"virginica\"] 순서일 때 0,1/ 0,2/ 1,2로 분할\n",
    "not_set = y_train[y_train != \"setosa\"] # 1,2\n",
    "not_ver = y_train[y_train != \"versicolor\"] # 0,2\n",
    "not_vir = y_train[y_train != \"virginica\"] # 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "y_not_set = pd.get_dummies(not_set, drop_first=True, columns=\"isVerginica\") # 2번 꽃인지 1번 꽃인지 파악\n",
    "y_not_ver = pd.get_dummies(not_ver, drop_first=True, columns=\"isVerginica\") # 2번 꽃인지 0번 꽃인지 파악\n",
    "y_not_vir = pd.get_dummies(not_vir, drop_first=True, columns=\"isSetosa\") # 1번 꽃인지 0번 꽃인지 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_1_OVO = SVC(kernel ='rbf', C = 5, gamma = 5) # 0 vs 1\n",
    "svm_2_OVO = SVC(kernel ='rbf', C = 5, gamma = 5) # 0 vs 2\n",
    "svm_3_OVO = SVC(kernel ='rbf', C = 5, gamma = 5) # 1 vs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 위한 X 데이터 생성\n",
    "x_not_set = X_train[y_train != \"setosa\"]\n",
    "x_not_ver = X_train[y_train != \"versicolor\"]\n",
    "x_not_vir = X_train[y_train != \"virginica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=5, gamma=5)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_1_OVO.fit(x_not_vir, y_not_vir) # 0 vs 1\n",
    "svm_2_OVO.fit(x_not_ver, y_not_ver) # 0 vs 2\n",
    "svm_3_OVO.fit(x_not_set, y_not_set) # 1 vs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_1_OVO.predict(X_test) # 결과 확인. svm_1_OVO는 1번 꽃으로 예측하면 1, 0번 꽃으로 예측하면 0을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_2_OVO.predict(X_test) # 결과 확인. svm_2_OVO는 2번 꽃으로 예측하면 1, 0번 꽃으로 예측하면 0을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_3_OVO.predict(X_test) # 결과 확인. svm_3_OVO는 2번 꽃으로 예측하면 1, 1번 꽃으로 예측하면 0을 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One vs One 의 경우는 총 예측기가 3개이며, 양자택일 하는 특성상 동점이 발생하지 않았다.\n",
    "\n",
    "따라서 단순히 Voting을 통해 2표 이상을 받은 클래스로 간주했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case 2 : One vs One SVM을 이 부분에 구현해주세요. (선택사항)\n",
    "\n",
    "\n",
    "def one_one_svm_predict(models, data, labels):\n",
    "    result = []\n",
    "    \n",
    "    for model in models: # 각 모델별로 예측하여 배열에 추가함\n",
    "        pred = model.predict(data)\n",
    "        result.append(pred)\n",
    "    \n",
    "    result = np.array(result).T # 배열을 넘파이 배열로 변경후 Transpose 수행\n",
    "    '''\n",
    "    result 배열의 구성은 다음과 같다.\n",
    "    row : x_test 데이터 한 개에 대한 예측값\n",
    "    col : 순서대로\n",
    "    [1번 0번 예측기 (1번일때 1반환), 2번 0번 예측기(2번일때 1반환), 2번 1번 예측기(2번일 때 1 반환)]\n",
    "    ''' \n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    # 각 예측기의 판단에 따라 전체 배열의 score를 올려 주겠다. (투표와 같은 방식으로 수행)   \n",
    "    for row in range(len(result)):\n",
    "        score = np.array([0, 0, 0])\n",
    "        \n",
    "        # 0번부터 순회함\n",
    "        if result[row][0] == 1: # 1번 꽃이다.\n",
    "            score[1] += 1\n",
    "        elif result[row][0] == 0: # 0번 꽃이다.\n",
    "            score[0] += 1\n",
    "            \n",
    "        if result[row][1] == 1: # 2번 꽃이다.\n",
    "            score[2] += 1\n",
    "        elif result[row][1] == 0: # 0번 꽃이다.\n",
    "            score[0] += 1\n",
    "            \n",
    "        if result[row][2] == 1: # 2번 꽃이다.\n",
    "            score[2] += 1\n",
    "        elif result[row][2] == 0: # 1번 꽃이다.\n",
    "            score[1] += 1\n",
    "    \n",
    "        pred.append(labels[score.argmax()]) # voting 된 점수를 꽃 이름으로 바꿔서 append\n",
    "    \n",
    "    \n",
    "    print(f\"prediction : \\n {result}\")\n",
    "    \n",
    "    return pred\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [svm_1_OVO, svm_2_OVO, svm_3_OVO]\n",
    "labels = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "\n",
    "prediction = one_one_svm_predict(models, X_test, labels)\n",
    "accuracy_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과는 one vs rest 와 같은 수치로 나오는 것을 확인할 수 있었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LlVlC9l9NX77",
    "outputId": "46f7603d-a673-498e-8a9e-a0cb79cc9468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원래 라이브러리가 제공하는 multi class SVM과 여러분이 구현한 multiclass SVM 결과를 비교해주세요\n",
    "from sklearn.model_selection import train_test_split #데이터셋 분리\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=48)\n",
    "\n",
    "svm_4 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
    "svm_4.fit(X_train_2, y_train_2)\n",
    "y_pred = svm_4.predict(X_test_2)\n",
    "\n",
    "accuracy_score(y_test_2,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn 라이브러리가 제공하는 classifier와 성능 차이가 크게 보이지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "assignment_1.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
